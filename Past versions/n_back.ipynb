{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9571a2-3794-481c-bbaf-7a732d06ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0c711b-adfd-491f-af0f-574aae094b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to convert movement idx to actual movement coordinates\n",
    "idx2mov = {0:np.array([0,0], dtype=int), \n",
    "               1:np.array([1,0], dtype=int), \n",
    "               2:np.array([-1,0], dtype=int), \n",
    "               3:np.array([0,1], dtype=int), \n",
    "               4:np.array([0,-1], dtype=int)}\n",
    "\n",
    "# Convert coordinate to flattened idx\n",
    "def loc2idx(loc, grid_size=np.array([5, 5], dtype=int)):\n",
    "    return loc[0]*grid_size[0] + loc[1]\n",
    "\n",
    "# Convert location flattened idx to coordinate\n",
    "def idx2loc(idx, grid_size=np.array([5, 5], dtype=int)):\n",
    "    return np.array([idx // grid_size[0], idx % grid_size[0]], dtype=int)\n",
    "\n",
    "\n",
    "def sample_n_back_spatial(n, p_stop=0.05, max_length=40, grid_size=np.array([5, 5], dtype=int), boundary='periodic', return_trajectory=False):\n",
    "    \"\"\"\n",
    "    Function to generate a sample for the n-back spatial task.\n",
    "\n",
    "    Args:\n",
    "    - n: response delay\n",
    "    - p_stop: after n steps, probability of stoping walk (default=0.05)\n",
    "    - max_length: maximum trajectory length (left zero-padding is applied to reach this length)\n",
    "    - grid_size (array-like): size of gridworld, must be odd (default=[5,5])\n",
    "    - boundary ['periodic', 'strict']: boundary conditions\n",
    "    - return_trajectory (bool): whether to return trajectory\n",
    "\n",
    "    Returns: movements (1D array, as index), n_back_idx (n-back location as idx), (trajectory) \n",
    "    \n",
    "    \"\"\"\n",
    "    assert boundary in ['periodic', 'strict'], \"boundary must be either 'periodic' or 'strict'\"\n",
    "    assert (grid_size[0] % 2 == 1) & (grid_size[1] % 2 == 1), \"grid size must be odd\"\n",
    "\n",
    "    zero = np.array([(grid_size[0]-1)//2, (grid_size[1]-1)//2], dtype=int)\n",
    "    movements = np.random.randint(5, size=np.minimum((n + stats.nbinom.rvs(1, p_stop)), max_length))\n",
    "    movements = np.concat(([0]*(max_length - movements.shape[0]), movements))\n",
    "    \n",
    "    trajectory = [zero]\n",
    "    \n",
    "    for idx in movements:\n",
    "        if boundary == 'periodic':\n",
    "            trajectory.append((trajectory[-1] + idx2mov[idx]) % grid_size)\n",
    "        elif boundary == 'strict':\n",
    "            trajectory.append(np.clip(trajectory[-1] + idx2mov[idx], a_min=[0,0], a_max=grid_size-1))\n",
    "        \n",
    "    trajectory = np.array(trajectory)\n",
    "\n",
    "    n_back_idx = loc2idx(trajectory[-(n+1)], grid_size=grid_size)\n",
    "\n",
    "    if return_trajectory:\n",
    "        return movements, n_back_idx, trajectory\n",
    "    else:\n",
    "        return movements, n_back_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac12feec-412f-4e0f-8943-df20a8f99588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 3, 1]),\n",
       " np.int64(10),\n",
       " array([[2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 1],\n",
       "        [2, 0],\n",
       "        [2, 1],\n",
       "        [3, 1]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_n_back_spatial(2, boundary='strict', return_trajectory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a012c0-84c3-49ca-a954-8998ac419056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class NBackDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\t\t\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "def create_n_back_dataset(num_samples, n, p_stop=0.05, max_length=40, grid_size=np.array([5, 5], dtype=int), boundary='periodic'):\n",
    "    X, Y = [], []\n",
    "    for _ in range(num_samples):\n",
    "        x, y = sample_n_back_spatial(n, p_stop=p_stop, max_length=max_length, grid_size=grid_size, boundary=boundary)\n",
    "        X.append(x); Y.append(y)\n",
    "\n",
    "    X = np.vstack(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    X = torch.tensor(X, dtype=int)\n",
    "    Y = torch.tensor(Y, dtype=int)\n",
    "\n",
    "    return NBackDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7a51e4-331c-4df5-a54b-3fb0b0aa69cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 4, 4, 0, 1, 1, 2, 1, 4, 0, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = create_n_back_dataset(100, 3)\n",
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571cd6cf-2325-4b45-aa58-7cee86f625e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class GRUExplorer(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_state_size, num_layers=1, grid_size=np.array([5, 5], dtype=int), dropout=0.2):\n",
    "\n",
    "        super(GRUExplorer, self).__init__()\n",
    "        \n",
    "        self.hidden_state_size = hidden_state_size\n",
    "        self.output_size = grid_size[0]*grid_size[1]\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.core = nn.GRU(5, self.hidden_state_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.head = nn.Linear(self.hidden_state_size, self.output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        X = F.one_hot(X, num_classes=5).to(torch.float32)\n",
    "        h0 = torch.zeros(self.num_layers, X.size(0), self.hidden_state_size).to(X.device)\n",
    "        \n",
    "        states, _ = self.core(X, h0)\n",
    "        logits = self.head(self.dropout(states[:, -1, :]))\n",
    "        return torch.softmax(logits, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba650137-8b2c-4668-8eed-70c11a140203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5900aadc-fe63-4479-ad65-544d4bcfe1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b88de844-1cff-4d03-8335-13105c72212c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.218820  [ 1000/100000]\n",
      "loss: 3.218240  [11000/100000]\n",
      "loss: 3.217492  [21000/100000]\n",
      "loss: 3.215131  [31000/100000]\n",
      "loss: 3.190426  [41000/100000]\n",
      "loss: 3.164490  [51000/100000]\n",
      "loss: 3.154604  [61000/100000]\n",
      "loss: 3.176247  [71000/100000]\n",
      "loss: 3.187088  [81000/100000]\n",
      "loss: 3.171196  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 3.178144 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.183963  [ 1000/100000]\n",
      "loss: 3.186887  [11000/100000]\n",
      "loss: 3.189767  [21000/100000]\n",
      "loss: 3.163234  [31000/100000]\n",
      "loss: 3.168090  [41000/100000]\n",
      "loss: 3.163948  [51000/100000]\n",
      "loss: 3.155600  [61000/100000]\n",
      "loss: 3.175726  [71000/100000]\n",
      "loss: 3.185841  [81000/100000]\n",
      "loss: 3.170514  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 3.176605 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.181616  [ 1000/100000]\n",
      "loss: 3.183036  [11000/100000]\n",
      "loss: 3.186191  [21000/100000]\n",
      "loss: 3.161292  [31000/100000]\n",
      "loss: 3.162568  [41000/100000]\n",
      "loss: 3.156693  [51000/100000]\n",
      "loss: 3.144412  [61000/100000]\n",
      "loss: 3.158818  [71000/100000]\n",
      "loss: 3.167406  [81000/100000]\n",
      "loss: 3.157490  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 10.8%, Avg loss: 3.165690 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.171561  [ 1000/100000]\n",
      "loss: 3.163095  [11000/100000]\n",
      "loss: 3.166118  [21000/100000]\n",
      "loss: 3.151327  [31000/100000]\n",
      "loss: 3.146660  [41000/100000]\n",
      "loss: 3.154104  [51000/100000]\n",
      "loss: 3.144920  [61000/100000]\n",
      "loss: 3.155746  [71000/100000]\n",
      "loss: 3.162458  [81000/100000]\n",
      "loss: 3.156803  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 12.7%, Avg loss: 3.164970 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.171080  [ 1000/100000]\n",
      "loss: 3.161790  [11000/100000]\n",
      "loss: 3.164637  [21000/100000]\n",
      "loss: 3.149850  [31000/100000]\n",
      "loss: 3.147820  [41000/100000]\n",
      "loss: 3.150421  [51000/100000]\n",
      "loss: 3.140202  [61000/100000]\n",
      "loss: 3.155926  [71000/100000]\n",
      "loss: 3.161862  [81000/100000]\n",
      "loss: 3.155365  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 14.1%, Avg loss: 3.163454 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.169564  [ 1000/100000]\n",
      "loss: 3.160343  [11000/100000]\n",
      "loss: 3.162426  [21000/100000]\n",
      "loss: 3.147174  [31000/100000]\n",
      "loss: 3.142491  [41000/100000]\n",
      "loss: 3.145568  [51000/100000]\n",
      "loss: 3.136849  [61000/100000]\n",
      "loss: 3.148563  [71000/100000]\n",
      "loss: 3.143668  [81000/100000]\n",
      "loss: 3.128349  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 18.5%, Avg loss: 3.125994 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.140067  [ 1000/100000]\n",
      "loss: 3.129228  [11000/100000]\n",
      "loss: 3.122273  [21000/100000]\n",
      "loss: 3.097009  [31000/100000]\n",
      "loss: 3.095570  [41000/100000]\n",
      "loss: 3.089732  [51000/100000]\n",
      "loss: 3.075655  [61000/100000]\n",
      "loss: 3.071442  [71000/100000]\n",
      "loss: 3.065874  [81000/100000]\n",
      "loss: 3.048733  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 31.8%, Avg loss: 3.038855 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.067976  [ 1000/100000]\n",
      "loss: 3.054735  [11000/100000]\n",
      "loss: 3.044277  [21000/100000]\n",
      "loss: 3.007789  [31000/100000]\n",
      "loss: 3.016856  [41000/100000]\n",
      "loss: 3.005559  [51000/100000]\n",
      "loss: 2.996664  [61000/100000]\n",
      "loss: 2.983113  [71000/100000]\n",
      "loss: 2.993289  [81000/100000]\n",
      "loss: 2.979513  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 37.4%, Avg loss: 2.975759 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.005675  [ 1000/100000]\n",
      "loss: 2.998793  [11000/100000]\n",
      "loss: 3.000145  [21000/100000]\n",
      "loss: 2.963295  [31000/100000]\n",
      "loss: 2.974681  [41000/100000]\n",
      "loss: 2.975370  [51000/100000]\n",
      "loss: 2.959655  [61000/100000]\n",
      "loss: 2.947448  [71000/100000]\n",
      "loss: 2.958237  [81000/100000]\n",
      "loss: 2.947370  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 42.1%, Avg loss: 2.950519 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.980228  [ 1000/100000]\n",
      "loss: 2.973044  [11000/100000]\n",
      "loss: 2.969045  [21000/100000]\n",
      "loss: 2.937376  [31000/100000]\n",
      "loss: 2.950969  [41000/100000]\n",
      "loss: 2.948339  [51000/100000]\n",
      "loss: 2.935798  [61000/100000]\n",
      "loss: 2.923947  [71000/100000]\n",
      "loss: 2.931827  [81000/100000]\n",
      "loss: 2.923167  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 2.922544 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.951380  [ 1000/100000]\n",
      "loss: 2.948553  [11000/100000]\n",
      "loss: 2.944404  [21000/100000]\n",
      "loss: 2.911281  [31000/100000]\n",
      "loss: 2.930622  [41000/100000]\n",
      "loss: 2.928130  [51000/100000]\n",
      "loss: 2.916221  [61000/100000]\n",
      "loss: 2.897482  [71000/100000]\n",
      "loss: 2.906103  [81000/100000]\n",
      "loss: 2.896819  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 2.900371 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.922571  [ 1000/100000]\n",
      "loss: 2.920977  [11000/100000]\n",
      "loss: 2.924102  [21000/100000]\n",
      "loss: 2.883864  [31000/100000]\n",
      "loss: 2.906886  [41000/100000]\n",
      "loss: 2.901860  [51000/100000]\n",
      "loss: 2.896589  [61000/100000]\n",
      "loss: 2.877449  [71000/100000]\n",
      "loss: 2.882526  [81000/100000]\n",
      "loss: 2.868781  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 2.872595 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.893754  [ 1000/100000]\n",
      "loss: 2.896068  [11000/100000]\n",
      "loss: 2.900876  [21000/100000]\n",
      "loss: 2.858287  [31000/100000]\n",
      "loss: 2.887195  [41000/100000]\n",
      "loss: 2.880761  [51000/100000]\n",
      "loss: 2.874086  [61000/100000]\n",
      "loss: 2.854720  [71000/100000]\n",
      "loss: 2.859944  [81000/100000]\n",
      "loss: 2.846208  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 2.849652 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.870142  [ 1000/100000]\n",
      "loss: 2.872133  [11000/100000]\n",
      "loss: 2.881501  [21000/100000]\n",
      "loss: 2.836385  [31000/100000]\n",
      "loss: 2.865856  [41000/100000]\n",
      "loss: 2.859604  [51000/100000]\n",
      "loss: 2.855119  [61000/100000]\n",
      "loss: 2.838346  [71000/100000]\n",
      "loss: 2.842541  [81000/100000]\n",
      "loss: 2.824651  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 2.828635 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2.849407  [ 1000/100000]\n",
      "loss: 2.855385  [11000/100000]\n",
      "loss: 2.864811  [21000/100000]\n",
      "loss: 2.815731  [31000/100000]\n",
      "loss: 2.846274  [41000/100000]\n",
      "loss: 2.841060  [51000/100000]\n",
      "loss: 2.835767  [61000/100000]\n",
      "loss: 2.819521  [71000/100000]\n",
      "loss: 2.823206  [81000/100000]\n",
      "loss: 2.810138  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 2.811663 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 2.831902  [ 1000/100000]\n",
      "loss: 2.838205  [11000/100000]\n",
      "loss: 2.848692  [21000/100000]\n",
      "loss: 2.798990  [31000/100000]\n",
      "loss: 2.831932  [41000/100000]\n",
      "loss: 2.827781  [51000/100000]\n",
      "loss: 2.819336  [61000/100000]\n",
      "loss: 2.806329  [71000/100000]\n",
      "loss: 2.810184  [81000/100000]\n",
      "loss: 2.791087  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 57.8%, Avg loss: 2.795587 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2.816436  [ 1000/100000]\n",
      "loss: 2.823078  [11000/100000]\n",
      "loss: 2.835215  [21000/100000]\n",
      "loss: 2.783939  [31000/100000]\n",
      "loss: 2.817692  [41000/100000]\n",
      "loss: 2.813992  [51000/100000]\n",
      "loss: 2.806466  [61000/100000]\n",
      "loss: 2.790982  [71000/100000]\n",
      "loss: 2.794901  [81000/100000]\n",
      "loss: 2.777971  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 2.780902 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 2.802034  [ 1000/100000]\n",
      "loss: 2.801800  [11000/100000]\n",
      "loss: 2.812397  [21000/100000]\n",
      "loss: 2.762070  [31000/100000]\n",
      "loss: 2.799970  [41000/100000]\n",
      "loss: 2.792511  [51000/100000]\n",
      "loss: 2.783333  [61000/100000]\n",
      "loss: 2.776102  [71000/100000]\n",
      "loss: 2.770377  [81000/100000]\n",
      "loss: 2.758649  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 2.765384 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 2.786290  [ 1000/100000]\n",
      "loss: 2.782054  [11000/100000]\n",
      "loss: 2.797663  [21000/100000]\n",
      "loss: 2.745561  [31000/100000]\n",
      "loss: 2.784376  [41000/100000]\n",
      "loss: 2.779989  [51000/100000]\n",
      "loss: 2.767934  [61000/100000]\n",
      "loss: 2.759204  [71000/100000]\n",
      "loss: 2.759565  [81000/100000]\n",
      "loss: 2.746006  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 2.749790 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 2.773539  [ 1000/100000]\n",
      "loss: 2.769061  [11000/100000]\n",
      "loss: 2.784914  [21000/100000]\n",
      "loss: 2.732493  [31000/100000]\n",
      "loss: 2.772580  [41000/100000]\n",
      "loss: 2.762448  [51000/100000]\n",
      "loss: 2.755514  [61000/100000]\n",
      "loss: 2.745609  [71000/100000]\n",
      "loss: 2.744900  [81000/100000]\n",
      "loss: 2.733740  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 2.737518 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2.760867  [ 1000/100000]\n",
      "loss: 2.758691  [11000/100000]\n",
      "loss: 2.772629  [21000/100000]\n",
      "loss: 2.716632  [31000/100000]\n",
      "loss: 2.760745  [41000/100000]\n",
      "loss: 2.752174  [51000/100000]\n",
      "loss: 2.744052  [61000/100000]\n",
      "loss: 2.733556  [71000/100000]\n",
      "loss: 2.734262  [81000/100000]\n",
      "loss: 2.721907  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 2.727533 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2.749873  [ 1000/100000]\n",
      "loss: 2.745066  [11000/100000]\n",
      "loss: 2.762704  [21000/100000]\n",
      "loss: 2.705210  [31000/100000]\n",
      "loss: 2.752472  [41000/100000]\n",
      "loss: 2.739148  [51000/100000]\n",
      "loss: 2.730338  [61000/100000]\n",
      "loss: 2.722294  [71000/100000]\n",
      "loss: 2.724425  [81000/100000]\n",
      "loss: 2.713382  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 2.717087 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 2.738343  [ 1000/100000]\n",
      "loss: 2.734397  [11000/100000]\n",
      "loss: 2.751750  [21000/100000]\n",
      "loss: 2.697076  [31000/100000]\n",
      "loss: 2.741595  [41000/100000]\n",
      "loss: 2.726495  [51000/100000]\n",
      "loss: 2.719151  [61000/100000]\n",
      "loss: 2.708885  [71000/100000]\n",
      "loss: 2.713164  [81000/100000]\n",
      "loss: 2.703825  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 2.707587 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2.729459  [ 1000/100000]\n",
      "loss: 2.723667  [11000/100000]\n",
      "loss: 2.743836  [21000/100000]\n",
      "loss: 2.686402  [31000/100000]\n",
      "loss: 2.730491  [41000/100000]\n",
      "loss: 2.718289  [51000/100000]\n",
      "loss: 2.709281  [61000/100000]\n",
      "loss: 2.693799  [71000/100000]\n",
      "loss: 2.703042  [81000/100000]\n",
      "loss: 2.692289  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 2.697909 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 2.719029  [ 1000/100000]\n",
      "loss: 2.715222  [11000/100000]\n",
      "loss: 2.736185  [21000/100000]\n",
      "loss: 2.672381  [31000/100000]\n",
      "loss: 2.722679  [41000/100000]\n",
      "loss: 2.703369  [51000/100000]\n",
      "loss: 2.694057  [61000/100000]\n",
      "loss: 2.685411  [71000/100000]\n",
      "loss: 2.695301  [81000/100000]\n",
      "loss: 2.684618  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 2.687269 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2.706693  [ 1000/100000]\n",
      "loss: 2.702542  [11000/100000]\n",
      "loss: 2.727190  [21000/100000]\n",
      "loss: 2.663698  [31000/100000]\n",
      "loss: 2.708910  [41000/100000]\n",
      "loss: 2.692978  [51000/100000]\n",
      "loss: 2.683071  [61000/100000]\n",
      "loss: 2.675044  [71000/100000]\n",
      "loss: 2.681598  [81000/100000]\n",
      "loss: 2.674177  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 2.674595 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2.692723  [ 1000/100000]\n",
      "loss: 2.694196  [11000/100000]\n",
      "loss: 2.714586  [21000/100000]\n",
      "loss: 2.651208  [31000/100000]\n",
      "loss: 2.699044  [41000/100000]\n",
      "loss: 2.682448  [51000/100000]\n",
      "loss: 2.671862  [61000/100000]\n",
      "loss: 2.664535  [71000/100000]\n",
      "loss: 2.672594  [81000/100000]\n",
      "loss: 2.663334  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 2.664559 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2.681486  [ 1000/100000]\n",
      "loss: 2.685053  [11000/100000]\n",
      "loss: 2.708174  [21000/100000]\n",
      "loss: 2.643490  [31000/100000]\n",
      "loss: 2.690649  [41000/100000]\n",
      "loss: 2.672862  [51000/100000]\n",
      "loss: 2.661141  [61000/100000]\n",
      "loss: 2.656603  [71000/100000]\n",
      "loss: 2.664274  [81000/100000]\n",
      "loss: 2.654052  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 2.655734 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.671244  [ 1000/100000]\n",
      "loss: 2.674267  [11000/100000]\n",
      "loss: 2.699270  [21000/100000]\n",
      "loss: 2.633382  [31000/100000]\n",
      "loss: 2.682139  [41000/100000]\n",
      "loss: 2.662273  [51000/100000]\n",
      "loss: 2.654320  [61000/100000]\n",
      "loss: 2.648710  [71000/100000]\n",
      "loss: 2.655118  [81000/100000]\n",
      "loss: 2.645203  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 2.647755 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.660494  [ 1000/100000]\n",
      "loss: 2.666314  [11000/100000]\n",
      "loss: 2.692491  [21000/100000]\n",
      "loss: 2.626186  [31000/100000]\n",
      "loss: 2.675427  [41000/100000]\n",
      "loss: 2.655452  [51000/100000]\n",
      "loss: 2.646977  [61000/100000]\n",
      "loss: 2.641955  [71000/100000]\n",
      "loss: 2.649096  [81000/100000]\n",
      "loss: 2.639750  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 2.642823 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 2.656663  [ 1000/100000]\n",
      "loss: 2.660494  [11000/100000]\n",
      "loss: 2.686170  [21000/100000]\n",
      "loss: 2.621584  [31000/100000]\n",
      "loss: 2.668110  [41000/100000]\n",
      "loss: 2.649757  [51000/100000]\n",
      "loss: 2.640343  [61000/100000]\n",
      "loss: 2.634002  [71000/100000]\n",
      "loss: 2.643157  [81000/100000]\n",
      "loss: 2.633924  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 2.638466 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 2.653251  [ 1000/100000]\n",
      "loss: 2.654089  [11000/100000]\n",
      "loss: 2.680521  [21000/100000]\n",
      "loss: 2.615436  [31000/100000]\n",
      "loss: 2.662741  [41000/100000]\n",
      "loss: 2.646017  [51000/100000]\n",
      "loss: 2.635073  [61000/100000]\n",
      "loss: 2.628418  [71000/100000]\n",
      "loss: 2.637136  [81000/100000]\n",
      "loss: 2.629106  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 2.632410 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 2.644330  [ 1000/100000]\n",
      "loss: 2.648202  [11000/100000]\n",
      "loss: 2.675680  [21000/100000]\n",
      "loss: 2.609456  [31000/100000]\n",
      "loss: 2.657247  [41000/100000]\n",
      "loss: 2.638738  [51000/100000]\n",
      "loss: 2.630044  [61000/100000]\n",
      "loss: 2.623776  [71000/100000]\n",
      "loss: 2.631590  [81000/100000]\n",
      "loss: 2.623443  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 2.628473 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.638547  [ 1000/100000]\n",
      "loss: 2.642994  [11000/100000]\n",
      "loss: 2.670920  [21000/100000]\n",
      "loss: 2.604942  [31000/100000]\n",
      "loss: 2.652177  [41000/100000]\n",
      "loss: 2.635972  [51000/100000]\n",
      "loss: 2.627748  [61000/100000]\n",
      "loss: 2.620660  [71000/100000]\n",
      "loss: 2.627228  [81000/100000]\n",
      "loss: 2.620195  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 2.620534 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 2.630309  [ 1000/100000]\n",
      "loss: 2.639680  [11000/100000]\n",
      "loss: 2.667062  [21000/100000]\n",
      "loss: 2.602016  [31000/100000]\n",
      "loss: 2.647145  [41000/100000]\n",
      "loss: 2.630698  [51000/100000]\n",
      "loss: 2.622252  [61000/100000]\n",
      "loss: 2.617624  [71000/100000]\n",
      "loss: 2.624036  [81000/100000]\n",
      "loss: 2.615023  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 2.616895 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 2.626506  [ 1000/100000]\n",
      "loss: 2.636033  [11000/100000]\n",
      "loss: 2.663692  [21000/100000]\n",
      "loss: 2.599058  [31000/100000]\n",
      "loss: 2.642639  [41000/100000]\n",
      "loss: 2.628019  [51000/100000]\n",
      "loss: 2.616591  [61000/100000]\n",
      "loss: 2.611447  [71000/100000]\n",
      "loss: 2.621005  [81000/100000]\n",
      "loss: 2.611985  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 2.613840 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 2.623533  [ 1000/100000]\n",
      "loss: 2.632115  [11000/100000]\n",
      "loss: 2.660606  [21000/100000]\n",
      "loss: 2.595269  [31000/100000]\n",
      "loss: 2.639711  [41000/100000]\n",
      "loss: 2.624679  [51000/100000]\n",
      "loss: 2.613576  [61000/100000]\n",
      "loss: 2.609451  [71000/100000]\n",
      "loss: 2.617322  [81000/100000]\n",
      "loss: 2.608482  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 2.610395 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 2.619184  [ 1000/100000]\n",
      "loss: 2.628228  [11000/100000]\n",
      "loss: 2.659027  [21000/100000]\n",
      "loss: 2.592144  [31000/100000]\n",
      "loss: 2.637293  [41000/100000]\n",
      "loss: 2.620749  [51000/100000]\n",
      "loss: 2.611223  [61000/100000]\n",
      "loss: 2.605271  [71000/100000]\n",
      "loss: 2.614977  [81000/100000]\n",
      "loss: 2.605907  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.606484 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 2.616188  [ 1000/100000]\n",
      "loss: 2.626580  [11000/100000]\n",
      "loss: 2.655080  [21000/100000]\n",
      "loss: 2.590279  [31000/100000]\n",
      "loss: 2.634974  [41000/100000]\n",
      "loss: 2.618002  [51000/100000]\n",
      "loss: 2.608757  [61000/100000]\n",
      "loss: 2.602406  [71000/100000]\n",
      "loss: 2.613243  [81000/100000]\n",
      "loss: 2.604203  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 2.606033 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 2.614882  [ 1000/100000]\n",
      "loss: 2.624775  [11000/100000]\n",
      "loss: 2.653040  [21000/100000]\n",
      "loss: 2.589101  [31000/100000]\n",
      "loss: 2.633140  [41000/100000]\n",
      "loss: 2.617014  [51000/100000]\n",
      "loss: 2.605925  [61000/100000]\n",
      "loss: 2.600346  [71000/100000]\n",
      "loss: 2.610337  [81000/100000]\n",
      "loss: 2.600682  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 2.605154 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 2.615081  [ 1000/100000]\n",
      "loss: 2.621643  [11000/100000]\n",
      "loss: 2.652314  [21000/100000]\n",
      "loss: 2.587117  [31000/100000]\n",
      "loss: 2.632649  [41000/100000]\n",
      "loss: 2.615852  [51000/100000]\n",
      "loss: 2.603711  [61000/100000]\n",
      "loss: 2.599095  [71000/100000]\n",
      "loss: 2.608983  [81000/100000]\n",
      "loss: 2.598057  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.602279 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 2.611221  [ 1000/100000]\n",
      "loss: 2.619840  [11000/100000]\n",
      "loss: 2.652239  [21000/100000]\n",
      "loss: 2.585714  [31000/100000]\n",
      "loss: 2.630977  [41000/100000]\n",
      "loss: 2.613965  [51000/100000]\n",
      "loss: 2.601951  [61000/100000]\n",
      "loss: 2.596408  [71000/100000]\n",
      "loss: 2.607743  [81000/100000]\n",
      "loss: 2.597666  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.598895 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 2.607692  [ 1000/100000]\n",
      "loss: 2.618362  [11000/100000]\n",
      "loss: 2.649937  [21000/100000]\n",
      "loss: 2.586449  [31000/100000]\n",
      "loss: 2.628082  [41000/100000]\n",
      "loss: 2.613155  [51000/100000]\n",
      "loss: 2.601462  [61000/100000]\n",
      "loss: 2.594647  [71000/100000]\n",
      "loss: 2.605730  [81000/100000]\n",
      "loss: 2.595811  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.597766 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 2.606077  [ 1000/100000]\n",
      "loss: 2.617644  [11000/100000]\n",
      "loss: 2.646036  [21000/100000]\n",
      "loss: 2.581473  [31000/100000]\n",
      "loss: 2.626337  [41000/100000]\n",
      "loss: 2.610422  [51000/100000]\n",
      "loss: 2.599696  [61000/100000]\n",
      "loss: 2.593513  [71000/100000]\n",
      "loss: 2.605044  [81000/100000]\n",
      "loss: 2.593894  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.596162 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 2.604865  [ 1000/100000]\n",
      "loss: 2.615489  [11000/100000]\n",
      "loss: 2.644686  [21000/100000]\n",
      "loss: 2.580609  [31000/100000]\n",
      "loss: 2.624196  [41000/100000]\n",
      "loss: 2.609888  [51000/100000]\n",
      "loss: 2.599175  [61000/100000]\n",
      "loss: 2.592543  [71000/100000]\n",
      "loss: 2.605292  [81000/100000]\n",
      "loss: 2.592244  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.596381 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 2.603869  [ 1000/100000]\n",
      "loss: 2.614659  [11000/100000]\n",
      "loss: 2.643805  [21000/100000]\n",
      "loss: 2.578966  [31000/100000]\n",
      "loss: 2.623459  [41000/100000]\n",
      "loss: 2.608586  [51000/100000]\n",
      "loss: 2.596623  [61000/100000]\n",
      "loss: 2.592649  [71000/100000]\n",
      "loss: 2.602966  [81000/100000]\n",
      "loss: 2.591681  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.594204 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 2.602551  [ 1000/100000]\n",
      "loss: 2.613524  [11000/100000]\n",
      "loss: 2.643445  [21000/100000]\n",
      "loss: 2.577352  [31000/100000]\n",
      "loss: 2.622021  [41000/100000]\n",
      "loss: 2.607934  [51000/100000]\n",
      "loss: 2.596046  [61000/100000]\n",
      "loss: 2.590838  [71000/100000]\n",
      "loss: 2.601137  [81000/100000]\n",
      "loss: 2.589697  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.592818 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 2.601323  [ 1000/100000]\n",
      "loss: 2.612806  [11000/100000]\n",
      "loss: 2.641314  [21000/100000]\n",
      "loss: 2.575850  [31000/100000]\n",
      "loss: 2.621537  [41000/100000]\n",
      "loss: 2.606719  [51000/100000]\n",
      "loss: 2.595549  [61000/100000]\n",
      "loss: 2.590270  [71000/100000]\n",
      "loss: 2.600183  [81000/100000]\n",
      "loss: 2.589597  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.591668 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 2.599577  [ 1000/100000]\n",
      "loss: 2.611196  [11000/100000]\n",
      "loss: 2.640420  [21000/100000]\n",
      "loss: 2.575469  [31000/100000]\n",
      "loss: 2.619812  [41000/100000]\n",
      "loss: 2.606698  [51000/100000]\n",
      "loss: 2.594482  [61000/100000]\n",
      "loss: 2.590030  [71000/100000]\n",
      "loss: 2.598928  [81000/100000]\n",
      "loss: 2.588261  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.591041 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 2.598480  [ 1000/100000]\n",
      "loss: 2.610460  [11000/100000]\n",
      "loss: 2.640473  [21000/100000]\n",
      "loss: 2.574816  [31000/100000]\n",
      "loss: 2.619025  [41000/100000]\n",
      "loss: 2.604993  [51000/100000]\n",
      "loss: 2.594607  [61000/100000]\n",
      "loss: 2.588963  [71000/100000]\n",
      "loss: 2.598436  [81000/100000]\n",
      "loss: 2.588101  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.590242 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 2.598319  [ 1000/100000]\n",
      "loss: 2.610046  [11000/100000]\n",
      "loss: 2.639248  [21000/100000]\n",
      "loss: 2.573502  [31000/100000]\n",
      "loss: 2.618736  [41000/100000]\n",
      "loss: 2.604097  [51000/100000]\n",
      "loss: 2.593036  [61000/100000]\n",
      "loss: 2.587237  [71000/100000]\n",
      "loss: 2.598454  [81000/100000]\n",
      "loss: 2.586354  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.589161 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 2.597113  [ 1000/100000]\n",
      "loss: 2.609071  [11000/100000]\n",
      "loss: 2.638759  [21000/100000]\n",
      "loss: 2.573071  [31000/100000]\n",
      "loss: 2.618248  [41000/100000]\n",
      "loss: 2.603874  [51000/100000]\n",
      "loss: 2.592669  [61000/100000]\n",
      "loss: 2.586848  [71000/100000]\n",
      "loss: 2.598290  [81000/100000]\n",
      "loss: 2.586605  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.589164 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 2.596264  [ 1000/100000]\n",
      "loss: 2.609091  [11000/100000]\n",
      "loss: 2.637177  [21000/100000]\n",
      "loss: 2.572573  [31000/100000]\n",
      "loss: 2.618184  [41000/100000]\n",
      "loss: 2.603627  [51000/100000]\n",
      "loss: 2.592470  [61000/100000]\n",
      "loss: 2.586221  [71000/100000]\n",
      "loss: 2.597247  [81000/100000]\n",
      "loss: 2.585451  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.589056 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 2.596058  [ 1000/100000]\n",
      "loss: 2.607435  [11000/100000]\n",
      "loss: 2.636870  [21000/100000]\n",
      "loss: 2.571469  [31000/100000]\n",
      "loss: 2.616187  [41000/100000]\n",
      "loss: 2.602772  [51000/100000]\n",
      "loss: 2.591048  [61000/100000]\n",
      "loss: 2.585631  [71000/100000]\n",
      "loss: 2.596590  [81000/100000]\n",
      "loss: 2.584644  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.587367 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 2.594645  [ 1000/100000]\n",
      "loss: 2.607042  [11000/100000]\n",
      "loss: 2.636019  [21000/100000]\n",
      "loss: 2.570694  [31000/100000]\n",
      "loss: 2.616648  [41000/100000]\n",
      "loss: 2.602481  [51000/100000]\n",
      "loss: 2.590924  [61000/100000]\n",
      "loss: 2.585195  [71000/100000]\n",
      "loss: 2.596003  [81000/100000]\n",
      "loss: 2.584352  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.587584 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 2.594147  [ 1000/100000]\n",
      "loss: 2.606841  [11000/100000]\n",
      "loss: 2.636271  [21000/100000]\n",
      "loss: 2.570591  [31000/100000]\n",
      "loss: 2.614667  [41000/100000]\n",
      "loss: 2.602266  [51000/100000]\n",
      "loss: 2.590509  [61000/100000]\n",
      "loss: 2.585174  [71000/100000]\n",
      "loss: 2.595505  [81000/100000]\n",
      "loss: 2.584166  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 2.587779 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 2.594203  [ 1000/100000]\n",
      "loss: 2.606593  [11000/100000]\n",
      "loss: 2.635484  [21000/100000]\n",
      "loss: 2.569881  [31000/100000]\n",
      "loss: 2.614479  [41000/100000]\n",
      "loss: 2.601836  [51000/100000]\n",
      "loss: 2.589872  [61000/100000]\n",
      "loss: 2.584475  [71000/100000]\n",
      "loss: 2.595248  [81000/100000]\n",
      "loss: 2.583485  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.586179 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 2.593444  [ 1000/100000]\n",
      "loss: 2.605704  [11000/100000]\n",
      "loss: 2.634950  [21000/100000]\n",
      "loss: 2.569525  [31000/100000]\n",
      "loss: 2.614104  [41000/100000]\n",
      "loss: 2.601074  [51000/100000]\n",
      "loss: 2.589194  [61000/100000]\n",
      "loss: 2.584173  [71000/100000]\n",
      "loss: 2.595312  [81000/100000]\n",
      "loss: 2.582499  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.585507 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 2.592486  [ 1000/100000]\n",
      "loss: 2.605520  [11000/100000]\n",
      "loss: 2.634812  [21000/100000]\n",
      "loss: 2.568865  [31000/100000]\n",
      "loss: 2.613621  [41000/100000]\n",
      "loss: 2.600761  [51000/100000]\n",
      "loss: 2.588825  [61000/100000]\n",
      "loss: 2.583202  [71000/100000]\n",
      "loss: 2.593929  [81000/100000]\n",
      "loss: 2.582089  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.585120 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 2.592153  [ 1000/100000]\n",
      "loss: 2.605274  [11000/100000]\n",
      "loss: 2.635714  [21000/100000]\n",
      "loss: 2.568642  [31000/100000]\n",
      "loss: 2.614025  [41000/100000]\n",
      "loss: 2.600291  [51000/100000]\n",
      "loss: 2.589290  [61000/100000]\n",
      "loss: 2.582948  [71000/100000]\n",
      "loss: 2.593872  [81000/100000]\n",
      "loss: 2.582212  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.585164 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 2.592389  [ 1000/100000]\n",
      "loss: 2.604876  [11000/100000]\n",
      "loss: 2.633901  [21000/100000]\n",
      "loss: 2.567947  [31000/100000]\n",
      "loss: 2.613091  [41000/100000]\n",
      "loss: 2.599751  [51000/100000]\n",
      "loss: 2.588217  [61000/100000]\n",
      "loss: 2.583064  [71000/100000]\n",
      "loss: 2.593383  [81000/100000]\n",
      "loss: 2.581555  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 2.586610 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 2.592418  [ 1000/100000]\n",
      "loss: 2.604743  [11000/100000]\n",
      "loss: 2.633730  [21000/100000]\n",
      "loss: 2.567645  [31000/100000]\n",
      "loss: 2.612677  [41000/100000]\n",
      "loss: 2.599695  [51000/100000]\n",
      "loss: 2.588235  [61000/100000]\n",
      "loss: 2.582205  [71000/100000]\n",
      "loss: 2.593222  [81000/100000]\n",
      "loss: 2.581312  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.585360 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 2.591418  [ 1000/100000]\n",
      "loss: 2.604531  [11000/100000]\n",
      "loss: 2.633354  [21000/100000]\n",
      "loss: 2.567283  [31000/100000]\n",
      "loss: 2.612567  [41000/100000]\n",
      "loss: 2.599670  [51000/100000]\n",
      "loss: 2.587672  [61000/100000]\n",
      "loss: 2.582080  [71000/100000]\n",
      "loss: 2.593310  [81000/100000]\n",
      "loss: 2.580681  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.583235 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 2.591217  [ 1000/100000]\n",
      "loss: 2.604049  [11000/100000]\n",
      "loss: 2.633093  [21000/100000]\n",
      "loss: 2.567043  [31000/100000]\n",
      "loss: 2.612251  [41000/100000]\n",
      "loss: 2.599207  [51000/100000]\n",
      "loss: 2.587507  [61000/100000]\n",
      "loss: 2.581628  [71000/100000]\n",
      "loss: 2.592681  [81000/100000]\n",
      "loss: 2.580333  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.582979 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 2.590533  [ 1000/100000]\n",
      "loss: 2.603726  [11000/100000]\n",
      "loss: 2.632957  [21000/100000]\n",
      "loss: 2.566935  [31000/100000]\n",
      "loss: 2.612100  [41000/100000]\n",
      "loss: 2.599009  [51000/100000]\n",
      "loss: 2.587405  [61000/100000]\n",
      "loss: 2.581453  [71000/100000]\n",
      "loss: 2.592888  [81000/100000]\n",
      "loss: 2.580916  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.584156 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 2.591167  [ 1000/100000]\n",
      "loss: 2.604006  [11000/100000]\n",
      "loss: 2.632841  [21000/100000]\n",
      "loss: 2.566391  [31000/100000]\n",
      "loss: 2.611994  [41000/100000]\n",
      "loss: 2.598784  [51000/100000]\n",
      "loss: 2.587145  [61000/100000]\n",
      "loss: 2.581410  [71000/100000]\n",
      "loss: 2.592493  [81000/100000]\n",
      "loss: 2.580093  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.583016 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 2.590031  [ 1000/100000]\n",
      "loss: 2.603246  [11000/100000]\n",
      "loss: 2.632195  [21000/100000]\n",
      "loss: 2.566626  [31000/100000]\n",
      "loss: 2.611475  [41000/100000]\n",
      "loss: 2.598677  [51000/100000]\n",
      "loss: 2.586859  [61000/100000]\n",
      "loss: 2.580751  [71000/100000]\n",
      "loss: 2.592196  [81000/100000]\n",
      "loss: 2.580112  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.583822 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 2.590524  [ 1000/100000]\n",
      "loss: 2.603972  [11000/100000]\n",
      "loss: 2.633912  [21000/100000]\n",
      "loss: 2.567318  [31000/100000]\n",
      "loss: 2.611666  [41000/100000]\n",
      "loss: 2.598518  [51000/100000]\n",
      "loss: 2.586580  [61000/100000]\n",
      "loss: 2.582483  [71000/100000]\n",
      "loss: 2.592234  [81000/100000]\n",
      "loss: 2.579901  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.582677 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 2.589686  [ 1000/100000]\n",
      "loss: 2.602901  [11000/100000]\n",
      "loss: 2.631649  [21000/100000]\n",
      "loss: 2.565792  [31000/100000]\n",
      "loss: 2.611129  [41000/100000]\n",
      "loss: 2.598100  [51000/100000]\n",
      "loss: 2.586492  [61000/100000]\n",
      "loss: 2.580510  [71000/100000]\n",
      "loss: 2.591402  [81000/100000]\n",
      "loss: 2.579529  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.582356 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 2.589336  [ 1000/100000]\n",
      "loss: 2.602834  [11000/100000]\n",
      "loss: 2.631722  [21000/100000]\n",
      "loss: 2.565859  [31000/100000]\n",
      "loss: 2.610816  [41000/100000]\n",
      "loss: 2.597881  [51000/100000]\n",
      "loss: 2.586173  [61000/100000]\n",
      "loss: 2.580545  [71000/100000]\n",
      "loss: 2.591065  [81000/100000]\n",
      "loss: 2.579339  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.581718 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 2.589381  [ 1000/100000]\n",
      "loss: 2.602685  [11000/100000]\n",
      "loss: 2.631536  [21000/100000]\n",
      "loss: 2.565489  [31000/100000]\n",
      "loss: 2.610863  [41000/100000]\n",
      "loss: 2.597630  [51000/100000]\n",
      "loss: 2.585987  [61000/100000]\n",
      "loss: 2.580320  [71000/100000]\n",
      "loss: 2.590888  [81000/100000]\n",
      "loss: 2.579006  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.582114 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 2.589043  [ 1000/100000]\n",
      "loss: 2.602317  [11000/100000]\n",
      "loss: 2.631442  [21000/100000]\n",
      "loss: 2.565344  [31000/100000]\n",
      "loss: 2.610696  [41000/100000]\n",
      "loss: 2.598024  [51000/100000]\n",
      "loss: 2.585994  [61000/100000]\n",
      "loss: 2.581016  [71000/100000]\n",
      "loss: 2.590938  [81000/100000]\n",
      "loss: 2.578848  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.581697 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 2.588843  [ 1000/100000]\n",
      "loss: 2.602209  [11000/100000]\n",
      "loss: 2.631362  [21000/100000]\n",
      "loss: 2.565211  [31000/100000]\n",
      "loss: 2.610409  [41000/100000]\n",
      "loss: 2.597447  [51000/100000]\n",
      "loss: 2.585772  [61000/100000]\n",
      "loss: 2.579936  [71000/100000]\n",
      "loss: 2.590749  [81000/100000]\n",
      "loss: 2.578721  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.581683 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 2.588599  [ 1000/100000]\n",
      "loss: 2.602213  [11000/100000]\n",
      "loss: 2.630956  [21000/100000]\n",
      "loss: 2.565101  [31000/100000]\n",
      "loss: 2.610223  [41000/100000]\n",
      "loss: 2.597347  [51000/100000]\n",
      "loss: 2.585744  [61000/100000]\n",
      "loss: 2.583402  [71000/100000]\n",
      "loss: 2.590572  [81000/100000]\n",
      "loss: 2.579107  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.581640 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 2.588593  [ 1000/100000]\n",
      "loss: 2.602324  [11000/100000]\n",
      "loss: 2.632128  [21000/100000]\n",
      "loss: 2.565558  [31000/100000]\n",
      "loss: 2.611043  [41000/100000]\n",
      "loss: 2.597653  [51000/100000]\n",
      "loss: 2.585795  [61000/100000]\n",
      "loss: 2.579875  [71000/100000]\n",
      "loss: 2.590215  [81000/100000]\n",
      "loss: 2.578477  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.581257 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 2.588379  [ 1000/100000]\n",
      "loss: 2.602050  [11000/100000]\n",
      "loss: 2.630831  [21000/100000]\n",
      "loss: 2.564785  [31000/100000]\n",
      "loss: 2.610128  [41000/100000]\n",
      "loss: 2.597259  [51000/100000]\n",
      "loss: 2.585505  [61000/100000]\n",
      "loss: 2.579489  [71000/100000]\n",
      "loss: 2.590235  [81000/100000]\n",
      "loss: 2.578699  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.581186 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 2.588608  [ 1000/100000]\n",
      "loss: 2.601988  [11000/100000]\n",
      "loss: 2.630535  [21000/100000]\n",
      "loss: 2.564828  [31000/100000]\n",
      "loss: 2.610128  [41000/100000]\n",
      "loss: 2.597236  [51000/100000]\n",
      "loss: 2.585344  [61000/100000]\n",
      "loss: 2.579602  [71000/100000]\n",
      "loss: 2.590187  [81000/100000]\n",
      "loss: 2.578143  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.580601 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 2.588358  [ 1000/100000]\n",
      "loss: 2.601641  [11000/100000]\n",
      "loss: 2.630558  [21000/100000]\n",
      "loss: 2.564600  [31000/100000]\n",
      "loss: 2.609790  [41000/100000]\n",
      "loss: 2.596942  [51000/100000]\n",
      "loss: 2.585129  [61000/100000]\n",
      "loss: 2.579215  [71000/100000]\n",
      "loss: 2.589934  [81000/100000]\n",
      "loss: 2.578223  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.581028 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 2.588034  [ 1000/100000]\n",
      "loss: 2.601561  [11000/100000]\n",
      "loss: 2.630528  [21000/100000]\n",
      "loss: 2.564492  [31000/100000]\n",
      "loss: 2.609786  [41000/100000]\n",
      "loss: 2.596731  [51000/100000]\n",
      "loss: 2.584932  [61000/100000]\n",
      "loss: 2.579282  [71000/100000]\n",
      "loss: 2.590441  [81000/100000]\n",
      "loss: 2.581482  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.585725 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 2.590594  [ 1000/100000]\n",
      "loss: 2.604082  [11000/100000]\n",
      "loss: 2.630724  [21000/100000]\n",
      "loss: 2.564823  [31000/100000]\n",
      "loss: 2.609622  [41000/100000]\n",
      "loss: 2.596711  [51000/100000]\n",
      "loss: 2.585342  [61000/100000]\n",
      "loss: 2.579132  [71000/100000]\n",
      "loss: 2.590081  [81000/100000]\n",
      "loss: 2.578045  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.580349 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 2.587924  [ 1000/100000]\n",
      "loss: 2.601452  [11000/100000]\n",
      "loss: 2.630184  [21000/100000]\n",
      "loss: 2.564208  [31000/100000]\n",
      "loss: 2.609607  [41000/100000]\n",
      "loss: 2.596706  [51000/100000]\n",
      "loss: 2.584869  [61000/100000]\n",
      "loss: 2.579180  [71000/100000]\n",
      "loss: 2.589682  [81000/100000]\n",
      "loss: 2.577844  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.580863 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 2.587762  [ 1000/100000]\n",
      "loss: 2.601224  [11000/100000]\n",
      "loss: 2.630208  [21000/100000]\n",
      "loss: 2.564203  [31000/100000]\n",
      "loss: 2.609512  [41000/100000]\n",
      "loss: 2.596423  [51000/100000]\n",
      "loss: 2.584902  [61000/100000]\n",
      "loss: 2.579077  [71000/100000]\n",
      "loss: 2.589812  [81000/100000]\n",
      "loss: 2.577703  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.581150 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 2.587889  [ 1000/100000]\n",
      "loss: 2.601298  [11000/100000]\n",
      "loss: 2.630238  [21000/100000]\n",
      "loss: 2.564101  [31000/100000]\n",
      "loss: 2.609192  [41000/100000]\n",
      "loss: 2.596396  [51000/100000]\n",
      "loss: 2.584682  [61000/100000]\n",
      "loss: 2.578876  [71000/100000]\n",
      "loss: 2.589828  [81000/100000]\n",
      "loss: 2.578510  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.581973 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 2.589625  [ 1000/100000]\n",
      "loss: 2.605437  [11000/100000]\n",
      "loss: 2.690925  [21000/100000]\n",
      "loss: 2.586546  [31000/100000]\n",
      "loss: 2.614477  [41000/100000]\n",
      "loss: 2.601172  [51000/100000]\n",
      "loss: 2.585518  [61000/100000]\n",
      "loss: 2.579243  [71000/100000]\n",
      "loss: 2.589595  [81000/100000]\n",
      "loss: 2.577779  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.580254 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 2.587712  [ 1000/100000]\n",
      "loss: 2.601231  [11000/100000]\n",
      "loss: 2.630004  [21000/100000]\n",
      "loss: 2.564015  [31000/100000]\n",
      "loss: 2.609284  [41000/100000]\n",
      "loss: 2.596433  [51000/100000]\n",
      "loss: 2.584645  [61000/100000]\n",
      "loss: 2.578727  [71000/100000]\n",
      "loss: 2.589303  [81000/100000]\n",
      "loss: 2.577572  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.580110 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 2.587394  [ 1000/100000]\n",
      "loss: 2.601144  [11000/100000]\n",
      "loss: 2.630024  [21000/100000]\n",
      "loss: 2.563890  [31000/100000]\n",
      "loss: 2.609275  [41000/100000]\n",
      "loss: 2.596201  [51000/100000]\n",
      "loss: 2.584454  [61000/100000]\n",
      "loss: 2.578693  [71000/100000]\n",
      "loss: 2.589221  [81000/100000]\n",
      "loss: 2.577526  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.579916 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 2.587302  [ 1000/100000]\n",
      "loss: 2.601095  [11000/100000]\n",
      "loss: 2.629741  [21000/100000]\n",
      "loss: 2.563823  [31000/100000]\n",
      "loss: 2.609003  [41000/100000]\n",
      "loss: 2.596171  [51000/100000]\n",
      "loss: 2.584455  [61000/100000]\n",
      "loss: 2.578681  [71000/100000]\n",
      "loss: 2.589252  [81000/100000]\n",
      "loss: 2.577504  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.580034 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 2.587313  [ 1000/100000]\n",
      "loss: 2.601083  [11000/100000]\n",
      "loss: 2.629795  [21000/100000]\n",
      "loss: 2.563803  [31000/100000]\n",
      "loss: 2.609093  [41000/100000]\n",
      "loss: 2.596153  [51000/100000]\n",
      "loss: 2.584390  [61000/100000]\n",
      "loss: 2.578588  [71000/100000]\n",
      "loss: 2.589080  [81000/100000]\n",
      "loss: 2.577538  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.579763 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 2.587265  [ 1000/100000]\n",
      "loss: 2.600941  [11000/100000]\n",
      "loss: 2.629761  [21000/100000]\n",
      "loss: 2.563686  [31000/100000]\n",
      "loss: 2.608848  [41000/100000]\n",
      "loss: 2.596032  [51000/100000]\n",
      "loss: 2.584246  [61000/100000]\n",
      "loss: 2.578397  [71000/100000]\n",
      "loss: 2.589156  [81000/100000]\n",
      "loss: 2.577399  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.579720 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 2.587230  [ 1000/100000]\n",
      "loss: 2.600891  [11000/100000]\n",
      "loss: 2.629670  [21000/100000]\n",
      "loss: 2.563830  [31000/100000]\n",
      "loss: 2.608852  [41000/100000]\n",
      "loss: 2.595886  [51000/100000]\n",
      "loss: 2.584210  [61000/100000]\n",
      "loss: 2.578514  [71000/100000]\n",
      "loss: 2.589066  [81000/100000]\n",
      "loss: 2.577373  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.579728 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 2.587060  [ 1000/100000]\n",
      "loss: 2.600860  [11000/100000]\n",
      "loss: 2.629655  [21000/100000]\n",
      "loss: 2.563587  [31000/100000]\n",
      "loss: 2.608876  [41000/100000]\n",
      "loss: 2.595866  [51000/100000]\n",
      "loss: 2.584239  [61000/100000]\n",
      "loss: 2.578340  [71000/100000]\n",
      "loss: 2.588977  [81000/100000]\n",
      "loss: 2.577261  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.579597 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 2.587138  [ 1000/100000]\n",
      "loss: 2.600721  [11000/100000]\n",
      "loss: 2.629565  [21000/100000]\n",
      "loss: 2.563546  [31000/100000]\n",
      "loss: 2.608751  [41000/100000]\n",
      "loss: 2.595798  [51000/100000]\n",
      "loss: 2.584353  [61000/100000]\n",
      "loss: 2.578229  [71000/100000]\n",
      "loss: 2.589108  [81000/100000]\n",
      "loss: 2.577140  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.580277 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 2.587168  [ 1000/100000]\n",
      "loss: 2.600708  [11000/100000]\n",
      "loss: 2.629513  [21000/100000]\n",
      "loss: 2.563525  [31000/100000]\n",
      "loss: 2.608686  [41000/100000]\n",
      "loss: 2.595922  [51000/100000]\n",
      "loss: 2.584115  [61000/100000]\n",
      "loss: 2.578223  [71000/100000]\n",
      "loss: 2.588723  [81000/100000]\n",
      "loss: 2.577127  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.579990 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 2.586973  [ 1000/100000]\n",
      "loss: 2.600914  [11000/100000]\n",
      "loss: 2.630085  [21000/100000]\n",
      "loss: 2.567162  [31000/100000]\n",
      "loss: 2.610544  [41000/100000]\n",
      "loss: 2.597130  [51000/100000]\n",
      "loss: 2.585768  [61000/100000]\n",
      "loss: 2.578956  [71000/100000]\n",
      "loss: 2.589132  [81000/100000]\n",
      "loss: 2.577261  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.579642 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 2.587180  [ 1000/100000]\n",
      "loss: 2.600593  [11000/100000]\n",
      "loss: 2.629482  [21000/100000]\n",
      "loss: 2.563415  [31000/100000]\n",
      "loss: 2.608626  [41000/100000]\n",
      "loss: 2.595724  [51000/100000]\n",
      "loss: 2.583966  [61000/100000]\n",
      "loss: 2.578087  [71000/100000]\n",
      "loss: 2.588857  [81000/100000]\n",
      "loss: 2.577095  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.579416 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 2.587006  [ 1000/100000]\n",
      "loss: 2.600553  [11000/100000]\n",
      "loss: 2.629462  [21000/100000]\n",
      "loss: 2.563407  [31000/100000]\n",
      "loss: 2.608580  [41000/100000]\n",
      "loss: 2.595655  [51000/100000]\n",
      "loss: 2.584050  [61000/100000]\n",
      "loss: 2.578168  [71000/100000]\n",
      "loss: 2.588816  [81000/100000]\n",
      "loss: 2.577111  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.579499 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 2.586849  [ 1000/100000]\n",
      "loss: 2.600546  [11000/100000]\n",
      "loss: 2.629323  [21000/100000]\n",
      "loss: 2.563276  [31000/100000]\n",
      "loss: 2.608628  [41000/100000]\n",
      "loss: 2.595653  [51000/100000]\n",
      "loss: 2.583959  [61000/100000]\n",
      "loss: 2.578329  [71000/100000]\n",
      "loss: 2.588956  [81000/100000]\n",
      "loss: 2.577211  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.579478 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 2.586969  [ 1000/100000]\n",
      "loss: 2.600518  [11000/100000]\n",
      "loss: 2.629304  [21000/100000]\n",
      "loss: 2.563190  [31000/100000]\n",
      "loss: 2.608542  [41000/100000]\n",
      "loss: 2.595499  [51000/100000]\n",
      "loss: 2.583927  [61000/100000]\n",
      "loss: 2.578240  [71000/100000]\n",
      "loss: 2.588723  [81000/100000]\n",
      "loss: 2.576864  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.579417 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 2.586782  [ 1000/100000]\n",
      "loss: 2.600510  [11000/100000]\n",
      "loss: 2.629387  [21000/100000]\n",
      "loss: 2.563222  [31000/100000]\n",
      "loss: 2.608465  [41000/100000]\n",
      "loss: 2.595504  [51000/100000]\n",
      "loss: 2.583777  [61000/100000]\n",
      "loss: 2.577986  [71000/100000]\n",
      "loss: 2.588629  [81000/100000]\n",
      "loss: 2.576836  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.579755 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 2.586687  [ 1000/100000]\n",
      "loss: 2.600370  [11000/100000]\n",
      "loss: 2.629146  [21000/100000]\n",
      "loss: 2.563211  [31000/100000]\n",
      "loss: 2.608538  [41000/100000]\n",
      "loss: 2.595548  [51000/100000]\n",
      "loss: 2.583792  [61000/100000]\n",
      "loss: 2.577826  [71000/100000]\n",
      "loss: 2.588662  [81000/100000]\n",
      "loss: 2.576784  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.580086 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "batch_size = 1000\n",
    "epochs = 100\n",
    "train_sample_size = 100_000\n",
    "test_sample_size = 1_000\n",
    "\n",
    "n_back = 0\n",
    "\n",
    "train_dataloader = DataLoader(create_n_back_dataset(train_sample_size, n_back, boundary='strict'), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(create_n_back_dataset(test_sample_size, n_back, boundary='strict'), batch_size=batch_size)\n",
    "\n",
    "model = GRUExplorer(64, num_layers=1).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33244e29-2a13-4f3e-b4da-31bc1d5e6cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f758a56-af16-4423-859e-42ba4a49be95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
