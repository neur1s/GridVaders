{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9571a2-3794-481c-bbaf-7a732d06ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0c711b-adfd-491f-af0f-574aae094b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to convert movement idx to actual movement coordinates\n",
    "idx2mov = {0:np.array([0,0], dtype=int), \n",
    "               1:np.array([1,0], dtype=int), \n",
    "               2:np.array([-1,0], dtype=int), \n",
    "               3:np.array([0,1], dtype=int), \n",
    "               4:np.array([0,-1], dtype=int)}\n",
    "\n",
    "# Convert coordinate to flattened idx\n",
    "def loc2idx(loc, grid_size=np.array([5, 5], dtype=int)):\n",
    "    return loc[0]*grid_size[0] + loc[1]\n",
    "\n",
    "# Convert location flattened idx to coordinate\n",
    "def idx2loc(idx, grid_size=np.array([5, 5], dtype=int)):\n",
    "    return np.array([idx // grid_size[0], idx % grid_size[0]], dtype=int)\n",
    "\n",
    "\n",
    "def sample_n_back_spatial(n, p_stop=0.05, max_length=40, grid_size=np.array([5, 5], dtype=int), boundary='periodic', return_trajectory=False):\n",
    "    \"\"\"\n",
    "    Function to generate a sample for the n-back spatial task.\n",
    "\n",
    "    Args:\n",
    "    - n: response delay\n",
    "    - p_stop: after n steps, probability of stoping walk (default=0.05)\n",
    "    - max_length: maximum trajectory length (left zero-padding is applied to reach this length)\n",
    "    - grid_size (array-like): size of gridworld, must be odd (default=[5,5])\n",
    "    - boundary ['periodic', 'strict']: boundary conditions\n",
    "    - return_trajectory (bool): whether to return trajectory\n",
    "\n",
    "    Returns: movements (1D array, as index), n_back_idx (n-back location as idx), (trajectory) \n",
    "    \n",
    "    \"\"\"\n",
    "    assert boundary in ['periodic', 'strict'], \"boundary must be either 'periodic' or 'strict'\"\n",
    "    assert (grid_size[0] % 2 == 1) & (grid_size[1] % 2 == 1), \"grid size must be odd\"\n",
    "\n",
    "    zero = np.array([(grid_size[0]-1)//2, (grid_size[1]-1)//2], dtype=int)\n",
    "    movements = np.random.randint(5, size=np.minimum((n + stats.nbinom.rvs(1, p_stop)), max_length))\n",
    "    movements = np.concat(([0]*(max_length - movements.shape[0]), movements))\n",
    "    \n",
    "    trajectory = [zero]\n",
    "    \n",
    "    for idx in movements:\n",
    "        if boundary == 'periodic':\n",
    "            trajectory.append((trajectory[-1] + idx2mov[idx]) % grid_size)\n",
    "        elif boundary == 'strict':\n",
    "            trajectory.append(np.clip(trajectory[-1] + idx2mov[idx], a_min=[0,0], a_max=grid_size-1))\n",
    "        \n",
    "    trajectory = np.array(trajectory)\n",
    "\n",
    "    n_back_idx = loc2idx(trajectory[-(n+1)], grid_size=grid_size)\n",
    "\n",
    "    if return_trajectory:\n",
    "        return movements, n_back_idx, trajectory\n",
    "    else:\n",
    "        return movements, n_back_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac12feec-412f-4e0f-8943-df20a8f99588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        2, 2, 0, 1, 4, 0, 4, 2, 1, 1, 1, 3, 4, 1, 4, 1, 3, 0]),\n",
       " np.int64(20),\n",
       " array([[2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [2, 2],\n",
       "        [1, 2],\n",
       "        [0, 2],\n",
       "        [0, 2],\n",
       "        [1, 2],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [2, 0],\n",
       "        [3, 0],\n",
       "        [3, 1],\n",
       "        [3, 0],\n",
       "        [4, 0],\n",
       "        [4, 0],\n",
       "        [4, 0],\n",
       "        [4, 1],\n",
       "        [4, 1]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_n_back_spatial(2, boundary='strict', return_trajectory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a012c0-84c3-49ca-a954-8998ac419056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class NBackDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\t\t\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "def create_n_back_dataset(num_samples, n, p_stop=0.05, max_length=40, grid_size=np.array([5, 5], dtype=int), boundary='periodic'):\n",
    "    X, Y = [], []\n",
    "    for _ in range(num_samples):\n",
    "        x, y = sample_n_back_spatial(n, p_stop=p_stop, max_length=max_length, grid_size=grid_size, boundary=boundary)\n",
    "        X.append(x); Y.append(y)\n",
    "\n",
    "    X = np.vstack(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    X = torch.tensor(X, dtype=int)\n",
    "    Y = torch.tensor(Y, dtype=int)\n",
    "\n",
    "    return NBackDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7a51e4-331c-4df5-a54b-3fb0b0aa69cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 3, 2, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = create_n_back_dataset(100, 3)\n",
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571cd6cf-2325-4b45-aa58-7cee86f625e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class GRUExplorer(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_state_size, num_layers=1, grid_size=np.array([5, 5], dtype=int)):\n",
    "\n",
    "        super(GRUExplorer, self).__init__()\n",
    "        \n",
    "        self.hidden_state_size = hidden_state_size\n",
    "        self.output_size = grid_size[0]*grid_size[1]\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.core = nn.GRU(5, self.hidden_state_size, num_layers=num_layers, batch_first=True)\n",
    "        self.head = nn.Linear(self.hidden_state_size, self.output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        X = F.one_hot(X, num_classes=5).to(torch.float32)\n",
    "        h0 = torch.zeros(self.num_layers, X.size(0), self.hidden_state_size).to(X.device)\n",
    "        \n",
    "        states, _ = self.core(X, h0)\n",
    "        logits = self.head(states[:, -1, :])\n",
    "        return torch.softmax(logits, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba650137-8b2c-4668-8eed-70c11a140203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5900aadc-fe63-4479-ad65-544d4bcfe1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b88de844-1cff-4d03-8335-13105c72212c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.218928  [ 1000/100000]\n",
      "loss: 3.200762  [11000/100000]\n",
      "loss: 3.170301  [21000/100000]\n",
      "loss: 3.173358  [31000/100000]\n",
      "loss: 3.159544  [41000/100000]\n",
      "loss: 3.178230  [51000/100000]\n",
      "loss: 3.177174  [61000/100000]\n",
      "loss: 3.164636  [71000/100000]\n",
      "loss: 3.174176  [81000/100000]\n",
      "loss: 3.170059  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 11.4%, Avg loss: 3.171291 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.174491  [ 1000/100000]\n",
      "loss: 3.167292  [11000/100000]\n",
      "loss: 3.165274  [21000/100000]\n",
      "loss: 3.160968  [31000/100000]\n",
      "loss: 3.147416  [41000/100000]\n",
      "loss: 3.157187  [51000/100000]\n",
      "loss: 3.155884  [61000/100000]\n",
      "loss: 3.142081  [71000/100000]\n",
      "loss: 3.140184  [81000/100000]\n",
      "loss: 3.115326  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 18.6%, Avg loss: 3.106204 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.105327  [ 1000/100000]\n",
      "loss: 3.078622  [11000/100000]\n",
      "loss: 3.073691  [21000/100000]\n",
      "loss: 3.045848  [31000/100000]\n",
      "loss: 3.000147  [41000/100000]\n",
      "loss: 2.981981  [51000/100000]\n",
      "loss: 2.935691  [61000/100000]\n",
      "loss: 2.900173  [71000/100000]\n",
      "loss: 2.878696  [81000/100000]\n",
      "loss: 2.840491  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.776827 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.759205  [ 1000/100000]\n",
      "loss: 2.709454  [11000/100000]\n",
      "loss: 2.724545  [21000/100000]\n",
      "loss: 2.673456  [31000/100000]\n",
      "loss: 2.661688  [41000/100000]\n",
      "loss: 2.645995  [51000/100000]\n",
      "loss: 2.633178  [61000/100000]\n",
      "loss: 2.635594  [71000/100000]\n",
      "loss: 2.653892  [81000/100000]\n",
      "loss: 2.639852  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 2.618643 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.601417  [ 1000/100000]\n",
      "loss: 2.573343  [11000/100000]\n",
      "loss: 2.613088  [21000/100000]\n",
      "loss: 2.600904  [31000/100000]\n",
      "loss: 2.581326  [41000/100000]\n",
      "loss: 2.604146  [51000/100000]\n",
      "loss: 2.601380  [61000/100000]\n",
      "loss: 2.607455  [71000/100000]\n",
      "loss: 2.630866  [81000/100000]\n",
      "loss: 2.616475  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 2.603614 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.587173  [ 1000/100000]\n",
      "loss: 2.556525  [11000/100000]\n",
      "loss: 2.578839  [21000/100000]\n",
      "loss: 2.564404  [31000/100000]\n",
      "loss: 2.545797  [41000/100000]\n",
      "loss: 2.566389  [51000/100000]\n",
      "loss: 2.561127  [61000/100000]\n",
      "loss: 2.578366  [71000/100000]\n",
      "loss: 2.580059  [81000/100000]\n",
      "loss: 2.589924  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 2.564769 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.545586  [ 1000/100000]\n",
      "loss: 2.541664  [11000/100000]\n",
      "loss: 2.572211  [21000/100000]\n",
      "loss: 2.565164  [31000/100000]\n",
      "loss: 2.530834  [41000/100000]\n",
      "loss: 2.557377  [51000/100000]\n",
      "loss: 2.556664  [61000/100000]\n",
      "loss: 2.592923  [71000/100000]\n",
      "loss: 2.574800  [81000/100000]\n",
      "loss: 2.586778  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 2.565788 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.540526  [ 1000/100000]\n",
      "loss: 2.519997  [11000/100000]\n",
      "loss: 2.553447  [21000/100000]\n",
      "loss: 2.547183  [31000/100000]\n",
      "loss: 2.540297  [41000/100000]\n",
      "loss: 2.565827  [51000/100000]\n",
      "loss: 2.564034  [61000/100000]\n",
      "loss: 2.564138  [71000/100000]\n",
      "loss: 2.561432  [81000/100000]\n",
      "loss: 2.576125  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 2.553425 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.532025  [ 1000/100000]\n",
      "loss: 2.535328  [11000/100000]\n",
      "loss: 2.560478  [21000/100000]\n",
      "loss: 2.553574  [31000/100000]\n",
      "loss: 2.527309  [41000/100000]\n",
      "loss: 2.555822  [51000/100000]\n",
      "loss: 2.548232  [61000/100000]\n",
      "loss: 2.563982  [71000/100000]\n",
      "loss: 2.559696  [81000/100000]\n",
      "loss: 2.745268  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 21.9%, Avg loss: 3.067923 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.052844  [ 1000/100000]\n",
      "loss: 3.074378  [11000/100000]\n",
      "loss: 2.947327  [21000/100000]\n",
      "loss: 2.826715  [31000/100000]\n",
      "loss: 2.734730  [41000/100000]\n",
      "loss: 2.718424  [51000/100000]\n",
      "loss: 2.654718  [61000/100000]\n",
      "loss: 2.615302  [71000/100000]\n",
      "loss: 2.633476  [81000/100000]\n",
      "loss: 2.590024  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 2.563827 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.546478  [ 1000/100000]\n",
      "loss: 2.530175  [11000/100000]\n",
      "loss: 2.546961  [21000/100000]\n",
      "loss: 2.548317  [31000/100000]\n",
      "loss: 2.521979  [41000/100000]\n",
      "loss: 2.555464  [51000/100000]\n",
      "loss: 2.549721  [61000/100000]\n",
      "loss: 2.558838  [71000/100000]\n",
      "loss: 2.562351  [81000/100000]\n",
      "loss: 2.575804  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 2.549944 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.529999  [ 1000/100000]\n",
      "loss: 2.517124  [11000/100000]\n",
      "loss: 2.545061  [21000/100000]\n",
      "loss: 2.542727  [31000/100000]\n",
      "loss: 2.654683  [41000/100000]\n",
      "loss: 2.642470  [51000/100000]\n",
      "loss: 2.603535  [61000/100000]\n",
      "loss: 2.575478  [71000/100000]\n",
      "loss: 2.580603  [81000/100000]\n",
      "loss: 2.577593  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 2.554255 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.532535  [ 1000/100000]\n",
      "loss: 2.538519  [11000/100000]\n",
      "loss: 2.552817  [21000/100000]\n",
      "loss: 2.554616  [31000/100000]\n",
      "loss: 2.521855  [41000/100000]\n",
      "loss: 2.558341  [51000/100000]\n",
      "loss: 2.540418  [61000/100000]\n",
      "loss: 2.555184  [71000/100000]\n",
      "loss: 2.557207  [81000/100000]\n",
      "loss: 2.570003  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 2.548536 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.530227  [ 1000/100000]\n",
      "loss: 2.510263  [11000/100000]\n",
      "loss: 2.539687  [21000/100000]\n",
      "loss: 2.557230  [31000/100000]\n",
      "loss: 2.533964  [41000/100000]\n",
      "loss: 2.552352  [51000/100000]\n",
      "loss: 2.541520  [61000/100000]\n",
      "loss: 2.557003  [71000/100000]\n",
      "loss: 2.557999  [81000/100000]\n",
      "loss: 2.665331  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 2.557170 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2.541292  [ 1000/100000]\n",
      "loss: 2.552247  [11000/100000]\n",
      "loss: 2.555327  [21000/100000]\n",
      "loss: 2.544407  [31000/100000]\n",
      "loss: 2.515815  [41000/100000]\n",
      "loss: 2.552705  [51000/100000]\n",
      "loss: 2.541631  [61000/100000]\n",
      "loss: 2.557425  [71000/100000]\n",
      "loss: 2.558847  [81000/100000]\n",
      "loss: 2.573124  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 2.547962 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 2.528814  [ 1000/100000]\n",
      "loss: 2.510945  [11000/100000]\n",
      "loss: 2.541434  [21000/100000]\n",
      "loss: 2.551020  [31000/100000]\n",
      "loss: 2.515131  [41000/100000]\n",
      "loss: 2.550698  [51000/100000]\n",
      "loss: 2.538515  [61000/100000]\n",
      "loss: 2.554195  [71000/100000]\n",
      "loss: 2.556452  [81000/100000]\n",
      "loss: 2.570666  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 2.547470 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2.527393  [ 1000/100000]\n",
      "loss: 2.510636  [11000/100000]\n",
      "loss: 2.541128  [21000/100000]\n",
      "loss: 2.540996  [31000/100000]\n",
      "loss: 2.513495  [41000/100000]\n",
      "loss: 2.549948  [51000/100000]\n",
      "loss: 2.537156  [61000/100000]\n",
      "loss: 2.553754  [71000/100000]\n",
      "loss: 2.555144  [81000/100000]\n",
      "loss: 2.569402  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 2.547154 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 2.528187  [ 1000/100000]\n",
      "loss: 2.510357  [11000/100000]\n",
      "loss: 2.540944  [21000/100000]\n",
      "loss: 2.540839  [31000/100000]\n",
      "loss: 2.513340  [41000/100000]\n",
      "loss: 2.549767  [51000/100000]\n",
      "loss: 2.536960  [61000/100000]\n",
      "loss: 2.553597  [71000/100000]\n",
      "loss: 2.960822  [81000/100000]\n",
      "loss: 2.968539  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 34.0%, Avg loss: 2.952555 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 2.941187  [ 1000/100000]\n",
      "loss: 2.915301  [11000/100000]\n",
      "loss: 2.950832  [21000/100000]\n",
      "loss: 2.894005  [31000/100000]\n",
      "loss: 2.899368  [41000/100000]\n",
      "loss: 2.936667  [51000/100000]\n",
      "loss: 2.923886  [61000/100000]\n",
      "loss: 2.910285  [71000/100000]\n",
      "loss: 2.891213  [81000/100000]\n",
      "loss: 2.903592  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 2.880155 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 2.861588  [ 1000/100000]\n",
      "loss: 2.837927  [11000/100000]\n",
      "loss: 2.863464  [21000/100000]\n",
      "loss: 2.834990  [31000/100000]\n",
      "loss: 2.822765  [41000/100000]\n",
      "loss: 2.849193  [51000/100000]\n",
      "loss: 2.848067  [61000/100000]\n",
      "loss: 2.822155  [71000/100000]\n",
      "loss: 2.785818  [81000/100000]\n",
      "loss: 2.772284  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 2.750997 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2.728850  [ 1000/100000]\n",
      "loss: 2.683203  [11000/100000]\n",
      "loss: 2.697812  [21000/100000]\n",
      "loss: 2.672884  [31000/100000]\n",
      "loss: 2.628233  [41000/100000]\n",
      "loss: 2.655662  [51000/100000]\n",
      "loss: 2.633632  [61000/100000]\n",
      "loss: 2.628908  [71000/100000]\n",
      "loss: 2.608519  [81000/100000]\n",
      "loss: 2.610654  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 2.595630 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2.574862  [ 1000/100000]\n",
      "loss: 2.549208  [11000/100000]\n",
      "loss: 2.599297  [21000/100000]\n",
      "loss: 2.579364  [31000/100000]\n",
      "loss: 2.547223  [41000/100000]\n",
      "loss: 2.587148  [51000/100000]\n",
      "loss: 2.569844  [61000/100000]\n",
      "loss: 2.578635  [71000/100000]\n",
      "loss: 2.579044  [81000/100000]\n",
      "loss: 2.582914  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 2.567184 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 2.553756  [ 1000/100000]\n",
      "loss: 2.527096  [11000/100000]\n",
      "loss: 2.563020  [21000/100000]\n",
      "loss: 2.555868  [31000/100000]\n",
      "loss: 2.531835  [41000/100000]\n",
      "loss: 2.558998  [51000/100000]\n",
      "loss: 2.552192  [61000/100000]\n",
      "loss: 2.585252  [71000/100000]\n",
      "loss: 2.622301  [81000/100000]\n",
      "loss: 2.582670  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 2.567006 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2.551180  [ 1000/100000]\n",
      "loss: 2.575409  [11000/100000]\n",
      "loss: 2.568899  [21000/100000]\n",
      "loss: 2.551264  [31000/100000]\n",
      "loss: 2.542380  [41000/100000]\n",
      "loss: 2.561937  [51000/100000]\n",
      "loss: 2.562336  [61000/100000]\n",
      "loss: 2.561369  [71000/100000]\n",
      "loss: 2.567692  [81000/100000]\n",
      "loss: 2.577600  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 2.557707 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 2.539885  [ 1000/100000]\n",
      "loss: 2.541730  [11000/100000]\n",
      "loss: 2.558015  [21000/100000]\n",
      "loss: 2.553086  [31000/100000]\n",
      "loss: 2.816192  [41000/100000]\n",
      "loss: 2.743140  [51000/100000]\n",
      "loss: 2.704882  [61000/100000]\n",
      "loss: 2.644937  [71000/100000]\n",
      "loss: 2.612793  [81000/100000]\n",
      "loss: 2.601615  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 2.577537 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2.561158  [ 1000/100000]\n",
      "loss: 2.530851  [11000/100000]\n",
      "loss: 2.560828  [21000/100000]\n",
      "loss: 2.561325  [31000/100000]\n",
      "loss: 2.930639  [41000/100000]\n",
      "loss: 2.890484  [51000/100000]\n",
      "loss: 2.847713  [61000/100000]\n",
      "loss: 2.805373  [71000/100000]\n",
      "loss: 2.780663  [81000/100000]\n",
      "loss: 2.749966  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 2.710825 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2.688744  [ 1000/100000]\n",
      "loss: 2.633820  [11000/100000]\n",
      "loss: 2.644769  [21000/100000]\n",
      "loss: 2.620985  [31000/100000]\n",
      "loss: 2.858715  [41000/100000]\n",
      "loss: 2.868510  [51000/100000]\n",
      "loss: 2.829047  [61000/100000]\n",
      "loss: 2.823123  [71000/100000]\n",
      "loss: 2.806731  [81000/100000]\n",
      "loss: 2.796116  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 2.780764 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2.781203  [ 1000/100000]\n",
      "loss: 2.725218  [11000/100000]\n",
      "loss: 2.748847  [21000/100000]\n",
      "loss: 2.741236  [31000/100000]\n",
      "loss: 2.693676  [41000/100000]\n",
      "loss: 2.709617  [51000/100000]\n",
      "loss: 2.676015  [61000/100000]\n",
      "loss: 2.684290  [71000/100000]\n",
      "loss: 2.772558  [81000/100000]\n",
      "loss: 2.681794  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 2.662681 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.642293  [ 1000/100000]\n",
      "loss: 2.599738  [11000/100000]\n",
      "loss: 2.612107  [21000/100000]\n",
      "loss: 2.600374  [31000/100000]\n",
      "loss: 2.574272  [41000/100000]\n",
      "loss: 2.606659  [51000/100000]\n",
      "loss: 2.582666  [61000/100000]\n",
      "loss: 2.599327  [71000/100000]\n",
      "loss: 2.593306  [81000/100000]\n",
      "loss: 2.599522  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 2.578720 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.563905  [ 1000/100000]\n",
      "loss: 2.537096  [11000/100000]\n",
      "loss: 2.563930  [21000/100000]\n",
      "loss: 2.559754  [31000/100000]\n",
      "loss: 2.542624  [41000/100000]\n",
      "loss: 2.574155  [51000/100000]\n",
      "loss: 2.558645  [61000/100000]\n",
      "loss: 2.567739  [71000/100000]\n",
      "loss: 2.569893  [81000/100000]\n",
      "loss: 2.581149  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 2.560928 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 2.545027  [ 1000/100000]\n",
      "loss: 2.522915  [11000/100000]\n",
      "loss: 2.548120  [21000/100000]\n",
      "loss: 2.548213  [31000/100000]\n",
      "loss: 2.525102  [41000/100000]\n",
      "loss: 2.561610  [51000/100000]\n",
      "loss: 2.547485  [61000/100000]\n",
      "loss: 2.560569  [71000/100000]\n",
      "loss: 2.567689  [81000/100000]\n",
      "loss: 2.574321  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 2.555814 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 2.538795  [ 1000/100000]\n",
      "loss: 2.518988  [11000/100000]\n",
      "loss: 2.551161  [21000/100000]\n",
      "loss: 2.548675  [31000/100000]\n",
      "loss: 2.545636  [41000/100000]\n",
      "loss: 2.561482  [51000/100000]\n",
      "loss: 2.545615  [61000/100000]\n",
      "loss: 2.559969  [71000/100000]\n",
      "loss: 2.565667  [81000/100000]\n",
      "loss: 2.574827  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 2.554231 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 2.535812  [ 1000/100000]\n",
      "loss: 2.516045  [11000/100000]\n",
      "loss: 2.545759  [21000/100000]\n",
      "loss: 2.545261  [31000/100000]\n",
      "loss: 2.521461  [41000/100000]\n",
      "loss: 2.553982  [51000/100000]\n",
      "loss: 2.543915  [61000/100000]\n",
      "loss: 2.556770  [71000/100000]\n",
      "loss: 2.561246  [81000/100000]\n",
      "loss: 2.571766  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 2.552435 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.534021  [ 1000/100000]\n",
      "loss: 2.515832  [11000/100000]\n",
      "loss: 2.545437  [21000/100000]\n",
      "loss: 2.544633  [31000/100000]\n",
      "loss: 2.521166  [41000/100000]\n",
      "loss: 2.554033  [51000/100000]\n",
      "loss: 2.542254  [61000/100000]\n",
      "loss: 2.560470  [71000/100000]\n",
      "loss: 2.560217  [81000/100000]\n",
      "loss: 2.571570  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 2.552104 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 2.533572  [ 1000/100000]\n",
      "loss: 2.516288  [11000/100000]\n",
      "loss: 2.545164  [21000/100000]\n",
      "loss: 2.542569  [31000/100000]\n",
      "loss: 2.519033  [41000/100000]\n",
      "loss: 2.552727  [51000/100000]\n",
      "loss: 2.542064  [61000/100000]\n",
      "loss: 2.556194  [71000/100000]\n",
      "loss: 2.558682  [81000/100000]\n",
      "loss: 2.571419  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 2.551008 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 2.531551  [ 1000/100000]\n",
      "loss: 2.514163  [11000/100000]\n",
      "loss: 2.543946  [21000/100000]\n",
      "loss: 2.543372  [31000/100000]\n",
      "loss: 2.518850  [41000/100000]\n",
      "loss: 2.553063  [51000/100000]\n",
      "loss: 2.568063  [61000/100000]\n",
      "loss: 2.567716  [71000/100000]\n",
      "loss: 2.561619  [81000/100000]\n",
      "loss: 2.571358  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 2.551248 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 2.530627  [ 1000/100000]\n",
      "loss: 2.514214  [11000/100000]\n",
      "loss: 2.545902  [21000/100000]\n",
      "loss: 2.543935  [31000/100000]\n",
      "loss: 2.518782  [41000/100000]\n",
      "loss: 2.552482  [51000/100000]\n",
      "loss: 2.541657  [61000/100000]\n",
      "loss: 2.556983  [71000/100000]\n",
      "loss: 2.560021  [81000/100000]\n",
      "loss: 2.571394  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 2.551238 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 2.530478  [ 1000/100000]\n",
      "loss: 2.516972  [11000/100000]\n",
      "loss: 2.544671  [21000/100000]\n",
      "loss: 2.542225  [31000/100000]\n",
      "loss: 2.518696  [41000/100000]\n",
      "loss: 2.552433  [51000/100000]\n",
      "loss: 2.541421  [61000/100000]\n",
      "loss: 2.555809  [71000/100000]\n",
      "loss: 2.558863  [81000/100000]\n",
      "loss: 2.571053  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 2.550712 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 2.530329  [ 1000/100000]\n",
      "loss: 2.515837  [11000/100000]\n",
      "loss: 2.544610  [21000/100000]\n",
      "loss: 2.542120  [31000/100000]\n",
      "loss: 2.518581  [41000/100000]\n",
      "loss: 2.553320  [51000/100000]\n",
      "loss: 2.541333  [61000/100000]\n",
      "loss: 2.555105  [71000/100000]\n",
      "loss: 2.558328  [81000/100000]\n",
      "loss: 2.570923  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.550607 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 2.530244  [ 1000/100000]\n",
      "loss: 2.515756  [11000/100000]\n",
      "loss: 2.544524  [21000/100000]\n",
      "loss: 2.542038  [31000/100000]\n",
      "loss: 2.518501  [41000/100000]\n",
      "loss: 2.553207  [51000/100000]\n",
      "loss: 2.541213  [61000/100000]\n",
      "loss: 2.555645  [71000/100000]\n",
      "loss: 2.558219  [81000/100000]\n",
      "loss: 2.570816  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.550262 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 2.530152  [ 1000/100000]\n",
      "loss: 2.515665  [11000/100000]\n",
      "loss: 2.544432  [21000/100000]\n",
      "loss: 2.541958  [31000/100000]\n",
      "loss: 2.518421  [41000/100000]\n",
      "loss: 2.553121  [51000/100000]\n",
      "loss: 2.541528  [61000/100000]\n",
      "loss: 2.556545  [71000/100000]\n",
      "loss: 2.558190  [81000/100000]\n",
      "loss: 2.570763  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.550373 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 2.530112  [ 1000/100000]\n",
      "loss: 2.514630  [11000/100000]\n",
      "loss: 2.544379  [21000/100000]\n",
      "loss: 2.541904  [31000/100000]\n",
      "loss: 2.518366  [41000/100000]\n",
      "loss: 2.553048  [51000/100000]\n",
      "loss: 2.540025  [61000/100000]\n",
      "loss: 2.555480  [71000/100000]\n",
      "loss: 2.558072  [81000/100000]\n",
      "loss: 2.570647  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.550213 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 2.530015  [ 1000/100000]\n",
      "loss: 2.514597  [11000/100000]\n",
      "loss: 2.544268  [21000/100000]\n",
      "loss: 2.541820  [31000/100000]\n",
      "loss: 2.517288  [41000/100000]\n",
      "loss: 2.552959  [51000/100000]\n",
      "loss: 2.539952  [61000/100000]\n",
      "loss: 2.555405  [71000/100000]\n",
      "loss: 2.557995  [81000/100000]\n",
      "loss: 2.570561  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.550040 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 2.529946  [ 1000/100000]\n",
      "loss: 2.514520  [11000/100000]\n",
      "loss: 2.544181  [21000/100000]\n",
      "loss: 2.541748  [31000/100000]\n",
      "loss: 2.517207  [41000/100000]\n",
      "loss: 2.552886  [51000/100000]\n",
      "loss: 2.539884  [61000/100000]\n",
      "loss: 2.555340  [71000/100000]\n",
      "loss: 2.557919  [81000/100000]\n",
      "loss: 2.571484  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.550004 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 2.529891  [ 1000/100000]\n",
      "loss: 2.514426  [11000/100000]\n",
      "loss: 2.544119  [21000/100000]\n",
      "loss: 2.541680  [31000/100000]\n",
      "loss: 2.516140  [41000/100000]\n",
      "loss: 2.551830  [51000/100000]\n",
      "loss: 2.539834  [61000/100000]\n",
      "loss: 2.555271  [71000/100000]\n",
      "loss: 2.558161  [81000/100000]\n",
      "loss: 2.571410  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.549818 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 2.529825  [ 1000/100000]\n",
      "loss: 2.514392  [11000/100000]\n",
      "loss: 2.544024  [21000/100000]\n",
      "loss: 2.541625  [31000/100000]\n",
      "loss: 2.516098  [41000/100000]\n",
      "loss: 2.551798  [51000/100000]\n",
      "loss: 2.538796  [61000/100000]\n",
      "loss: 2.555265  [71000/100000]\n",
      "loss: 2.557348  [81000/100000]\n",
      "loss: 2.570405  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.549752 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 2.528800  [ 1000/100000]\n",
      "loss: 2.516318  [11000/100000]\n",
      "loss: 2.543967  [21000/100000]\n",
      "loss: 2.541606  [31000/100000]\n",
      "loss: 2.516040  [41000/100000]\n",
      "loss: 2.553868  [51000/100000]\n",
      "loss: 2.540819  [61000/100000]\n",
      "loss: 2.555632  [71000/100000]\n",
      "loss: 2.557763  [81000/100000]\n",
      "loss: 2.570413  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.549933 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 2.528779  [ 1000/100000]\n",
      "loss: 2.516241  [11000/100000]\n",
      "loss: 2.543904  [21000/100000]\n",
      "loss: 2.541589  [31000/100000]\n",
      "loss: 2.515994  [41000/100000]\n",
      "loss: 2.552693  [51000/100000]\n",
      "loss: 2.540704  [61000/100000]\n",
      "loss: 2.554485  [71000/100000]\n",
      "loss: 2.557726  [81000/100000]\n",
      "loss: 2.570261  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.549858 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 2.528697  [ 1000/100000]\n",
      "loss: 2.516178  [11000/100000]\n",
      "loss: 2.543826  [21000/100000]\n",
      "loss: 2.541512  [31000/100000]\n",
      "loss: 2.515906  [41000/100000]\n",
      "loss: 2.551617  [51000/100000]\n",
      "loss: 2.539631  [61000/100000]\n",
      "loss: 2.554421  [71000/100000]\n",
      "loss: 2.557666  [81000/100000]\n",
      "loss: 2.570192  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.549821 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 2.528636  [ 1000/100000]\n",
      "loss: 2.516122  [11000/100000]\n",
      "loss: 2.543772  [21000/100000]\n",
      "loss: 2.541454  [31000/100000]\n",
      "loss: 2.515835  [41000/100000]\n",
      "loss: 2.551557  [51000/100000]\n",
      "loss: 2.539572  [61000/100000]\n",
      "loss: 2.554363  [71000/100000]\n",
      "loss: 2.557609  [81000/100000]\n",
      "loss: 2.570125  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.549502 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 2.528448  [ 1000/100000]\n",
      "loss: 2.498283  [11000/100000]\n",
      "loss: 2.512780  [21000/100000]\n",
      "loss: 2.512262  [31000/100000]\n",
      "loss: 2.494807  [41000/100000]\n",
      "loss: 2.528157  [51000/100000]\n",
      "loss: 2.500100  [61000/100000]\n",
      "loss: 2.511429  [71000/100000]\n",
      "loss: 2.518088  [81000/100000]\n",
      "loss: 2.529952  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 2.513037 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 2.501213  [ 1000/100000]\n",
      "loss: 2.488536  [11000/100000]\n",
      "loss: 2.510320  [21000/100000]\n",
      "loss: 2.511084  [31000/100000]\n",
      "loss: 2.494214  [41000/100000]\n",
      "loss: 2.527778  [51000/100000]\n",
      "loss: 2.501338  [61000/100000]\n",
      "loss: 2.511069  [71000/100000]\n",
      "loss: 2.517269  [81000/100000]\n",
      "loss: 2.529669  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 2.512962 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 2.500940  [ 1000/100000]\n",
      "loss: 2.489310  [11000/100000]\n",
      "loss: 2.510107  [21000/100000]\n",
      "loss: 2.510835  [31000/100000]\n",
      "loss: 2.494053  [41000/100000]\n",
      "loss: 2.527625  [51000/100000]\n",
      "loss: 2.500150  [61000/100000]\n",
      "loss: 2.510823  [71000/100000]\n",
      "loss: 2.517025  [81000/100000]\n",
      "loss: 2.529429  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 2.512662 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 2.499773  [ 1000/100000]\n",
      "loss: 2.488141  [11000/100000]\n",
      "loss: 2.508951  [21000/100000]\n",
      "loss: 2.510672  [31000/100000]\n",
      "loss: 2.493908  [41000/100000]\n",
      "loss: 2.527496  [51000/100000]\n",
      "loss: 2.499941  [61000/100000]\n",
      "loss: 2.510641  [71000/100000]\n",
      "loss: 2.746199  [81000/100000]\n",
      "loss: 2.705002  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 2.623452 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 2.621726  [ 1000/100000]\n",
      "loss: 2.712039  [11000/100000]\n",
      "loss: 2.649814  [21000/100000]\n",
      "loss: 2.573596  [31000/100000]\n",
      "loss: 2.531798  [41000/100000]\n",
      "loss: 2.550577  [51000/100000]\n",
      "loss: 2.521919  [61000/100000]\n",
      "loss: 2.530848  [71000/100000]\n",
      "loss: 2.531252  [81000/100000]\n",
      "loss: 2.536617  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 2.516404 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 2.503398  [ 1000/100000]\n",
      "loss: 2.495466  [11000/100000]\n",
      "loss: 2.513843  [21000/100000]\n",
      "loss: 2.512975  [31000/100000]\n",
      "loss: 2.496088  [41000/100000]\n",
      "loss: 2.529919  [51000/100000]\n",
      "loss: 2.502819  [61000/100000]\n",
      "loss: 2.511491  [71000/100000]\n",
      "loss: 2.518342  [81000/100000]\n",
      "loss: 2.530971  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 2.515009 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 2.503340  [ 1000/100000]\n",
      "loss: 2.490593  [11000/100000]\n",
      "loss: 2.512007  [21000/100000]\n",
      "loss: 2.511325  [31000/100000]\n",
      "loss: 2.495382  [41000/100000]\n",
      "loss: 2.528941  [51000/100000]\n",
      "loss: 2.502386  [61000/100000]\n",
      "loss: 2.510998  [71000/100000]\n",
      "loss: 2.518913  [81000/100000]\n",
      "loss: 2.530569  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 2.514435 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 2.501984  [ 1000/100000]\n",
      "loss: 2.490354  [11000/100000]\n",
      "loss: 2.511680  [21000/100000]\n",
      "loss: 2.510845  [31000/100000]\n",
      "loss: 2.495076  [41000/100000]\n",
      "loss: 2.528684  [51000/100000]\n",
      "loss: 2.502114  [61000/100000]\n",
      "loss: 2.511751  [71000/100000]\n",
      "loss: 2.517652  [81000/100000]\n",
      "loss: 2.530338  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 2.514090 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 2.501780  [ 1000/100000]\n",
      "loss: 2.490214  [11000/100000]\n",
      "loss: 2.511527  [21000/100000]\n",
      "loss: 2.510668  [31000/100000]\n",
      "loss: 2.494895  [41000/100000]\n",
      "loss: 2.528577  [51000/100000]\n",
      "loss: 2.501951  [61000/100000]\n",
      "loss: 2.511615  [71000/100000]\n",
      "loss: 2.517535  [81000/100000]\n",
      "loss: 2.530195  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 2.513956 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 2.501643  [ 1000/100000]\n",
      "loss: 2.490127  [11000/100000]\n",
      "loss: 2.511423  [21000/100000]\n",
      "loss: 2.510542  [31000/100000]\n",
      "loss: 2.494780  [41000/100000]\n",
      "loss: 2.528470  [51000/100000]\n",
      "loss: 2.501838  [61000/100000]\n",
      "loss: 2.511510  [71000/100000]\n",
      "loss: 2.517443  [81000/100000]\n",
      "loss: 2.531086  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513748 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 2.501519  [ 1000/100000]\n",
      "loss: 2.490044  [11000/100000]\n",
      "loss: 2.511333  [21000/100000]\n",
      "loss: 2.510439  [31000/100000]\n",
      "loss: 2.494687  [41000/100000]\n",
      "loss: 2.528380  [51000/100000]\n",
      "loss: 2.501743  [61000/100000]\n",
      "loss: 2.511421  [71000/100000]\n",
      "loss: 2.517361  [81000/100000]\n",
      "loss: 2.530998  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513760 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 2.501409  [ 1000/100000]\n",
      "loss: 2.489972  [11000/100000]\n",
      "loss: 2.512254  [21000/100000]\n",
      "loss: 2.510358  [31000/100000]\n",
      "loss: 2.494615  [41000/100000]\n",
      "loss: 2.528317  [51000/100000]\n",
      "loss: 2.501665  [61000/100000]\n",
      "loss: 2.511345  [71000/100000]\n",
      "loss: 2.518286  [81000/100000]\n",
      "loss: 2.530927  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 2.513787 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 2.501305  [ 1000/100000]\n",
      "loss: 2.489917  [11000/100000]\n",
      "loss: 2.511176  [21000/100000]\n",
      "loss: 2.510292  [31000/100000]\n",
      "loss: 2.494555  [41000/100000]\n",
      "loss: 2.528254  [51000/100000]\n",
      "loss: 2.501586  [61000/100000]\n",
      "loss: 2.510280  [71000/100000]\n",
      "loss: 2.518225  [81000/100000]\n",
      "loss: 2.530878  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513555 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 2.501227  [ 1000/100000]\n",
      "loss: 2.489868  [11000/100000]\n",
      "loss: 2.511102  [21000/100000]\n",
      "loss: 2.510922  [31000/100000]\n",
      "loss: 2.494528  [41000/100000]\n",
      "loss: 2.528301  [51000/100000]\n",
      "loss: 2.501526  [61000/100000]\n",
      "loss: 2.511213  [71000/100000]\n",
      "loss: 2.518156  [81000/100000]\n",
      "loss: 2.530813  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513420 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 2.501127  [ 1000/100000]\n",
      "loss: 2.489821  [11000/100000]\n",
      "loss: 2.511021  [21000/100000]\n",
      "loss: 2.510162  [31000/100000]\n",
      "loss: 2.494499  [41000/100000]\n",
      "loss: 2.528148  [51000/100000]\n",
      "loss: 2.501446  [61000/100000]\n",
      "loss: 2.511126  [71000/100000]\n",
      "loss: 2.517096  [81000/100000]\n",
      "loss: 2.530751  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513247 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 2.501023  [ 1000/100000]\n",
      "loss: 2.489788  [11000/100000]\n",
      "loss: 2.510937  [21000/100000]\n",
      "loss: 2.510077  [31000/100000]\n",
      "loss: 2.494546  [41000/100000]\n",
      "loss: 2.528049  [51000/100000]\n",
      "loss: 2.501367  [61000/100000]\n",
      "loss: 2.511032  [71000/100000]\n",
      "loss: 2.517023  [81000/100000]\n",
      "loss: 2.530683  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513110 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 2.500914  [ 1000/100000]\n",
      "loss: 2.489743  [11000/100000]\n",
      "loss: 2.510848  [21000/100000]\n",
      "loss: 2.509990  [31000/100000]\n",
      "loss: 2.494629  [41000/100000]\n",
      "loss: 2.527975  [51000/100000]\n",
      "loss: 2.501298  [61000/100000]\n",
      "loss: 2.509947  [71000/100000]\n",
      "loss: 2.517947  [81000/100000]\n",
      "loss: 2.530622  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513072 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 2.500837  [ 1000/100000]\n",
      "loss: 2.489651  [11000/100000]\n",
      "loss: 2.510780  [21000/100000]\n",
      "loss: 2.509932  [31000/100000]\n",
      "loss: 2.494668  [41000/100000]\n",
      "loss: 2.527951  [51000/100000]\n",
      "loss: 2.501246  [61000/100000]\n",
      "loss: 2.510893  [71000/100000]\n",
      "loss: 2.516896  [81000/100000]\n",
      "loss: 2.530584  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512938 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 2.500777  [ 1000/100000]\n",
      "loss: 2.489600  [11000/100000]\n",
      "loss: 2.510740  [21000/100000]\n",
      "loss: 2.509901  [31000/100000]\n",
      "loss: 2.494652  [41000/100000]\n",
      "loss: 2.527927  [51000/100000]\n",
      "loss: 2.501209  [61000/100000]\n",
      "loss: 2.510859  [71000/100000]\n",
      "loss: 2.516859  [81000/100000]\n",
      "loss: 2.530554  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512815 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 2.500730  [ 1000/100000]\n",
      "loss: 2.488567  [11000/100000]\n",
      "loss: 2.510712  [21000/100000]\n",
      "loss: 2.509877  [31000/100000]\n",
      "loss: 2.494622  [41000/100000]\n",
      "loss: 2.527908  [51000/100000]\n",
      "loss: 2.501178  [61000/100000]\n",
      "loss: 2.510833  [71000/100000]\n",
      "loss: 2.516827  [81000/100000]\n",
      "loss: 2.530529  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512899 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 2.500688  [ 1000/100000]\n",
      "loss: 2.488541  [11000/100000]\n",
      "loss: 2.510689  [21000/100000]\n",
      "loss: 2.509858  [31000/100000]\n",
      "loss: 2.494593  [41000/100000]\n",
      "loss: 2.527892  [51000/100000]\n",
      "loss: 2.501150  [61000/100000]\n",
      "loss: 2.510812  [71000/100000]\n",
      "loss: 2.516801  [81000/100000]\n",
      "loss: 2.530508  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512879 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 2.500652  [ 1000/100000]\n",
      "loss: 2.488521  [11000/100000]\n",
      "loss: 2.510670  [21000/100000]\n",
      "loss: 2.509841  [31000/100000]\n",
      "loss: 2.494565  [41000/100000]\n",
      "loss: 2.527877  [51000/100000]\n",
      "loss: 2.501128  [61000/100000]\n",
      "loss: 2.510794  [71000/100000]\n",
      "loss: 2.516778  [81000/100000]\n",
      "loss: 2.531489  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512967 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 2.500620  [ 1000/100000]\n",
      "loss: 2.488503  [11000/100000]\n",
      "loss: 2.510653  [21000/100000]\n",
      "loss: 2.509826  [31000/100000]\n",
      "loss: 2.494539  [41000/100000]\n",
      "loss: 2.527864  [51000/100000]\n",
      "loss: 2.501107  [61000/100000]\n",
      "loss: 2.510778  [71000/100000]\n",
      "loss: 2.516758  [81000/100000]\n",
      "loss: 2.531472  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512803 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 2.500590  [ 1000/100000]\n",
      "loss: 2.488487  [11000/100000]\n",
      "loss: 2.510637  [21000/100000]\n",
      "loss: 2.509812  [31000/100000]\n",
      "loss: 2.494517  [41000/100000]\n",
      "loss: 2.527861  [51000/100000]\n",
      "loss: 2.501088  [61000/100000]\n",
      "loss: 2.509765  [71000/100000]\n",
      "loss: 2.517736  [81000/100000]\n",
      "loss: 2.531461  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513057 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 2.500561  [ 1000/100000]\n",
      "loss: 2.489474  [11000/100000]\n",
      "loss: 2.510647  [21000/100000]\n",
      "loss: 2.509796  [31000/100000]\n",
      "loss: 2.494503  [41000/100000]\n",
      "loss: 2.527838  [51000/100000]\n",
      "loss: 2.501070  [61000/100000]\n",
      "loss: 2.509748  [71000/100000]\n",
      "loss: 2.517715  [81000/100000]\n",
      "loss: 2.531444  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513063 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 2.500535  [ 1000/100000]\n",
      "loss: 2.488459  [11000/100000]\n",
      "loss: 2.510631  [21000/100000]\n",
      "loss: 2.509779  [31000/100000]\n",
      "loss: 2.494483  [41000/100000]\n",
      "loss: 2.527822  [51000/100000]\n",
      "loss: 2.501055  [61000/100000]\n",
      "loss: 2.509732  [71000/100000]\n",
      "loss: 2.517693  [81000/100000]\n",
      "loss: 2.531431  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512970 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 2.500509  [ 1000/100000]\n",
      "loss: 2.488446  [11000/100000]\n",
      "loss: 2.510596  [21000/100000]\n",
      "loss: 2.509762  [31000/100000]\n",
      "loss: 2.494460  [41000/100000]\n",
      "loss: 2.527800  [51000/100000]\n",
      "loss: 2.501033  [61000/100000]\n",
      "loss: 2.509718  [71000/100000]\n",
      "loss: 2.517671  [81000/100000]\n",
      "loss: 2.531419  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513193 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 2.500490  [ 1000/100000]\n",
      "loss: 2.489446  [11000/100000]\n",
      "loss: 2.510583  [21000/100000]\n",
      "loss: 2.509747  [31000/100000]\n",
      "loss: 2.494433  [41000/100000]\n",
      "loss: 2.527787  [51000/100000]\n",
      "loss: 2.501005  [61000/100000]\n",
      "loss: 2.508704  [71000/100000]\n",
      "loss: 2.517633  [81000/100000]\n",
      "loss: 2.531399  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512936 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 2.500470  [ 1000/100000]\n",
      "loss: 2.489430  [11000/100000]\n",
      "loss: 2.511591  [21000/100000]\n",
      "loss: 2.509722  [31000/100000]\n",
      "loss: 2.494423  [41000/100000]\n",
      "loss: 2.526762  [51000/100000]\n",
      "loss: 2.500992  [61000/100000]\n",
      "loss: 2.508672  [71000/100000]\n",
      "loss: 2.517589  [81000/100000]\n",
      "loss: 2.531387  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512805 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 2.500434  [ 1000/100000]\n",
      "loss: 2.489411  [11000/100000]\n",
      "loss: 2.510568  [21000/100000]\n",
      "loss: 2.509686  [31000/100000]\n",
      "loss: 2.494394  [41000/100000]\n",
      "loss: 2.526727  [51000/100000]\n",
      "loss: 2.500965  [61000/100000]\n",
      "loss: 2.508646  [71000/100000]\n",
      "loss: 2.517554  [81000/100000]\n",
      "loss: 2.531365  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512790 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 2.500397  [ 1000/100000]\n",
      "loss: 2.489396  [11000/100000]\n",
      "loss: 2.510550  [21000/100000]\n",
      "loss: 2.509663  [31000/100000]\n",
      "loss: 2.494364  [41000/100000]\n",
      "loss: 2.526704  [51000/100000]\n",
      "loss: 2.500948  [61000/100000]\n",
      "loss: 2.508627  [71000/100000]\n",
      "loss: 2.517531  [81000/100000]\n",
      "loss: 2.531348  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513067 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 2.500370  [ 1000/100000]\n",
      "loss: 2.489384  [11000/100000]\n",
      "loss: 2.510531  [21000/100000]\n",
      "loss: 2.509636  [31000/100000]\n",
      "loss: 2.494381  [41000/100000]\n",
      "loss: 2.526702  [51000/100000]\n",
      "loss: 2.500932  [61000/100000]\n",
      "loss: 2.508613  [71000/100000]\n",
      "loss: 2.517516  [81000/100000]\n",
      "loss: 2.531333  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.513049 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 2.500344  [ 1000/100000]\n",
      "loss: 2.489377  [11000/100000]\n",
      "loss: 2.510516  [21000/100000]\n",
      "loss: 2.509619  [31000/100000]\n",
      "loss: 2.494369  [41000/100000]\n",
      "loss: 2.526689  [51000/100000]\n",
      "loss: 2.500919  [61000/100000]\n",
      "loss: 2.508599  [71000/100000]\n",
      "loss: 2.517505  [81000/100000]\n",
      "loss: 2.531316  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512879 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 2.500315  [ 1000/100000]\n",
      "loss: 2.489372  [11000/100000]\n",
      "loss: 2.510500  [21000/100000]\n",
      "loss: 2.509606  [31000/100000]\n",
      "loss: 2.494357  [41000/100000]\n",
      "loss: 2.526666  [51000/100000]\n",
      "loss: 2.500906  [61000/100000]\n",
      "loss: 2.508589  [71000/100000]\n",
      "loss: 2.517494  [81000/100000]\n",
      "loss: 2.531302  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512867 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 2.500296  [ 1000/100000]\n",
      "loss: 2.489367  [11000/100000]\n",
      "loss: 2.510486  [21000/100000]\n",
      "loss: 2.509597  [31000/100000]\n",
      "loss: 2.494348  [41000/100000]\n",
      "loss: 2.526655  [51000/100000]\n",
      "loss: 2.500895  [61000/100000]\n",
      "loss: 2.508579  [71000/100000]\n",
      "loss: 2.517485  [81000/100000]\n",
      "loss: 2.531289  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512856 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 2.500279  [ 1000/100000]\n",
      "loss: 2.489364  [11000/100000]\n",
      "loss: 2.510475  [21000/100000]\n",
      "loss: 2.509589  [31000/100000]\n",
      "loss: 2.494340  [41000/100000]\n",
      "loss: 2.526644  [51000/100000]\n",
      "loss: 2.500885  [61000/100000]\n",
      "loss: 2.508570  [71000/100000]\n",
      "loss: 2.517475  [81000/100000]\n",
      "loss: 2.531273  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512846 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 2.500264  [ 1000/100000]\n",
      "loss: 2.489361  [11000/100000]\n",
      "loss: 2.510464  [21000/100000]\n",
      "loss: 2.509580  [31000/100000]\n",
      "loss: 2.494331  [41000/100000]\n",
      "loss: 2.526631  [51000/100000]\n",
      "loss: 2.500886  [61000/100000]\n",
      "loss: 2.508569  [71000/100000]\n",
      "loss: 2.517467  [81000/100000]\n",
      "loss: 2.531259  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512934 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 2.500249  [ 1000/100000]\n",
      "loss: 2.489360  [11000/100000]\n",
      "loss: 2.510453  [21000/100000]\n",
      "loss: 2.509569  [31000/100000]\n",
      "loss: 2.494301  [41000/100000]\n",
      "loss: 2.526617  [51000/100000]\n",
      "loss: 2.500862  [61000/100000]\n",
      "loss: 2.508549  [71000/100000]\n",
      "loss: 2.517456  [81000/100000]\n",
      "loss: 2.531239  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512624 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 2.500226  [ 1000/100000]\n",
      "loss: 2.490379  [11000/100000]\n",
      "loss: 2.511013  [21000/100000]\n",
      "loss: 2.509583  [31000/100000]\n",
      "loss: 2.494292  [41000/100000]\n",
      "loss: 2.527614  [51000/100000]\n",
      "loss: 2.502858  [61000/100000]\n",
      "loss: 2.509543  [71000/100000]\n",
      "loss: 2.518454  [81000/100000]\n",
      "loss: 2.530239  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512554 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 2.500207  [ 1000/100000]\n",
      "loss: 2.490331  [11000/100000]\n",
      "loss: 2.510913  [21000/100000]\n",
      "loss: 2.509554  [31000/100000]\n",
      "loss: 2.494289  [41000/100000]\n",
      "loss: 2.527586  [51000/100000]\n",
      "loss: 2.501842  [61000/100000]\n",
      "loss: 2.508561  [71000/100000]\n",
      "loss: 2.518492  [81000/100000]\n",
      "loss: 2.530242  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512789 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 2.500232  [ 1000/100000]\n",
      "loss: 2.490330  [11000/100000]\n",
      "loss: 2.509934  [21000/100000]\n",
      "loss: 2.509562  [31000/100000]\n",
      "loss: 2.494277  [41000/100000]\n",
      "loss: 2.527602  [51000/100000]\n",
      "loss: 2.501820  [61000/100000]\n",
      "loss: 2.508517  [71000/100000]\n",
      "loss: 2.518446  [81000/100000]\n",
      "loss: 2.530214  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512629 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 2.500195  [ 1000/100000]\n",
      "loss: 2.490315  [11000/100000]\n",
      "loss: 2.509905  [21000/100000]\n",
      "loss: 2.509529  [31000/100000]\n",
      "loss: 2.494270  [41000/100000]\n",
      "loss: 2.527557  [51000/100000]\n",
      "loss: 2.501797  [61000/100000]\n",
      "loss: 2.509503  [71000/100000]\n",
      "loss: 2.518407  [81000/100000]\n",
      "loss: 2.530190  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512711 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 2.500206  [ 1000/100000]\n",
      "loss: 2.490299  [11000/100000]\n",
      "loss: 2.509864  [21000/100000]\n",
      "loss: 2.509511  [31000/100000]\n",
      "loss: 2.494254  [41000/100000]\n",
      "loss: 2.527521  [51000/100000]\n",
      "loss: 2.501776  [61000/100000]\n",
      "loss: 2.509490  [71000/100000]\n",
      "loss: 2.518391  [81000/100000]\n",
      "loss: 2.530169  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512694 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 2.500185  [ 1000/100000]\n",
      "loss: 2.490288  [11000/100000]\n",
      "loss: 2.509835  [21000/100000]\n",
      "loss: 2.509495  [31000/100000]\n",
      "loss: 2.494246  [41000/100000]\n",
      "loss: 2.527496  [51000/100000]\n",
      "loss: 2.501760  [61000/100000]\n",
      "loss: 2.509474  [71000/100000]\n",
      "loss: 2.518375  [81000/100000]\n",
      "loss: 2.531157  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512581 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 2.500166  [ 1000/100000]\n",
      "loss: 2.490276  [11000/100000]\n",
      "loss: 2.509802  [21000/100000]\n",
      "loss: 2.509481  [31000/100000]\n",
      "loss: 2.494239  [41000/100000]\n",
      "loss: 2.527471  [51000/100000]\n",
      "loss: 2.501744  [61000/100000]\n",
      "loss: 2.509456  [71000/100000]\n",
      "loss: 2.518360  [81000/100000]\n",
      "loss: 2.531146  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512563 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 2.500144  [ 1000/100000]\n",
      "loss: 2.490273  [11000/100000]\n",
      "loss: 2.509770  [21000/100000]\n",
      "loss: 2.509470  [31000/100000]\n",
      "loss: 2.494228  [41000/100000]\n",
      "loss: 2.527442  [51000/100000]\n",
      "loss: 2.501726  [61000/100000]\n",
      "loss: 2.509433  [71000/100000]\n",
      "loss: 2.518345  [81000/100000]\n",
      "loss: 2.531134  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512544 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 2.500126  [ 1000/100000]\n",
      "loss: 2.490258  [11000/100000]\n",
      "loss: 2.509736  [21000/100000]\n",
      "loss: 2.509457  [31000/100000]\n",
      "loss: 2.494218  [41000/100000]\n",
      "loss: 2.527412  [51000/100000]\n",
      "loss: 2.501708  [61000/100000]\n",
      "loss: 2.509408  [71000/100000]\n",
      "loss: 2.518330  [81000/100000]\n",
      "loss: 2.531120  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512327 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 2.500108  [ 1000/100000]\n",
      "loss: 2.490238  [11000/100000]\n",
      "loss: 2.509708  [21000/100000]\n",
      "loss: 2.509446  [31000/100000]\n",
      "loss: 2.494205  [41000/100000]\n",
      "loss: 2.527384  [51000/100000]\n",
      "loss: 2.501691  [61000/100000]\n",
      "loss: 2.509388  [71000/100000]\n",
      "loss: 2.518317  [81000/100000]\n",
      "loss: 2.531107  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512313 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 2.500090  [ 1000/100000]\n",
      "loss: 2.490223  [11000/100000]\n",
      "loss: 2.509694  [21000/100000]\n",
      "loss: 2.509441  [31000/100000]\n",
      "loss: 2.494186  [41000/100000]\n",
      "loss: 2.527361  [51000/100000]\n",
      "loss: 2.501683  [61000/100000]\n",
      "loss: 2.509375  [71000/100000]\n",
      "loss: 2.517307  [81000/100000]\n",
      "loss: 2.531096  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512400 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 2.500080  [ 1000/100000]\n",
      "loss: 2.490212  [11000/100000]\n",
      "loss: 2.509669  [21000/100000]\n",
      "loss: 2.509428  [31000/100000]\n",
      "loss: 2.494183  [41000/100000]\n",
      "loss: 2.527352  [51000/100000]\n",
      "loss: 2.501673  [61000/100000]\n",
      "loss: 2.509366  [71000/100000]\n",
      "loss: 2.517301  [81000/100000]\n",
      "loss: 2.531087  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 2.512493 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "batch_size = 1000\n",
    "epochs = 100\n",
    "train_sample_size = 100_000\n",
    "test_sample_size = 10_000\n",
    "\n",
    "n_back = 0\n",
    "\n",
    "train_dataloader = DataLoader(create_n_back_dataset(train_sample_size, n_back, boundary='strict'), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(create_n_back_dataset(test_sample_size, n_back, boundary='strict'), batch_size=batch_size)\n",
    "\n",
    "model = GRUExplorer(128, num_layers=2).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33244e29-2a13-4f3e-b4da-31bc1d5e6cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
