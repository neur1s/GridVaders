{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9571a2-3794-481c-bbaf-7a732d06ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0c711b-adfd-491f-af0f-574aae094b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to convert movement idx to actual movement coordinates\n",
    "idx2mov = {0:np.array([0,0], dtype=int), \n",
    "               1:np.array([1,0], dtype=int), \n",
    "               2:np.array([-1,0], dtype=int), \n",
    "               3:np.array([0,1], dtype=int), \n",
    "               4:np.array([0,-1], dtype=int)}\n",
    "\n",
    "# Convert coordinate to flattened idx\n",
    "def loc2idx(loc, grid_size=np.array([5, 5], dtype=int)):\n",
    "    return loc[0]*grid_size[0] + loc[1]\n",
    "\n",
    "# Convert location flattened idx to coordinate\n",
    "def idx2loc(idx, grid_size=np.array([5, 5], dtype=int)):\n",
    "    return np.array([idx // grid_size[0], idx % grid_size[0]], dtype=int)\n",
    "\n",
    "\n",
    "def sample_n_back_spatial(n, p_stop=0.05, max_length=40, grid_size=np.array([5, 5], dtype=int), boundary='periodic', return_trajectory=False):\n",
    "    \"\"\"\n",
    "    Function to generate a sample for the n-back spatial task.\n",
    "\n",
    "    Args:\n",
    "    - n: response delay\n",
    "    - p_stop: after n steps, probability of stoping walk (default=0.05)\n",
    "    - max_length: maximum trajectory length (left zero-padding is applied to reach this length)\n",
    "    - grid_size (array-like): size of gridworld, must be odd (default=[5,5])\n",
    "    - boundary ['periodic', 'strict']: boundary conditions\n",
    "    - return_trajectory (bool): whether to return trajectory\n",
    "\n",
    "    Returns: movements (1D array, as index), n_back_idx (n-back location as idx), (trajectory) \n",
    "    \n",
    "    \"\"\"\n",
    "    assert boundary in ['periodic', 'strict'], \"boundary must be either 'periodic' or 'strict'\"\n",
    "    assert (grid_size[0] % 2 == 1) & (grid_size[1] % 2 == 1), \"grid size must be odd\"\n",
    "\n",
    "    zero = np.array([(grid_size[0]-1)//2, (grid_size[1]-1)//2], dtype=int)\n",
    "    movements = np.random.randint(5, size=np.minimum((n + stats.nbinom.rvs(1, p_stop)), max_length))\n",
    "    movements = np.concat(([0]*(max_length - movements.shape[0]), movements))\n",
    "    \n",
    "    trajectory = [zero]\n",
    "    \n",
    "    for idx in movements:\n",
    "        if boundary == 'periodic':\n",
    "            trajectory.append((trajectory[-1] + idx2mov[idx]) % grid_size)\n",
    "        elif boundary == 'strict':\n",
    "            trajectory.append(np.clip(trajectory[-1] + idx2mov[idx], a_min=[0,0], a_max=grid_size))\n",
    "        \n",
    "    trajectory = np.array(trajectory)\n",
    "\n",
    "    n_back_idx = loc2idx(trajectory[-(n+1)], grid_size=grid_size)\n",
    "\n",
    "    if return_trajectory:\n",
    "        return movements, n_back_idx, trajectory\n",
    "    else:\n",
    "        return movements, n_back_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a012c0-84c3-49ca-a954-8998ac419056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class NBackDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\t\t\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "def create_n_back_dataset(num_samples, n, p_stop=0.05, max_length=40, grid_size=np.array([5, 5], dtype=int), boundary='periodic'):\n",
    "    X, Y = [], []\n",
    "    for _ in range(num_samples):\n",
    "        x, y = sample_n_back_spatial(n, p_stop=p_stop, max_length=max_length, grid_size=grid_size, boundary=boundary)\n",
    "        X.append(x); Y.append(y)\n",
    "\n",
    "    X = np.vstack(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    X = torch.tensor(X, dtype=int)\n",
    "    Y = torch.tensor(Y, dtype=int)\n",
    "\n",
    "    return NBackDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7a51e4-331c-4df5-a54b-3fb0b0aa69cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 2, 3, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = create_n_back_dataset(100, 3)\n",
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571cd6cf-2325-4b45-aa58-7cee86f625e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class GRUExplorer(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_state_size, num_layers=1, grid_size=np.array([5, 5], dtype=int)):\n",
    "\n",
    "        super(GRUExplorer, self).__init__()\n",
    "        \n",
    "        self.hidden_state_size = hidden_state_size\n",
    "        self.output_size = grid_size[0]*grid_size[1]\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.core = nn.GRU(5, self.hidden_state_size, batch_first=True)\n",
    "        self.head = nn.Linear(self.hidden_state_size, self.output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        X = F.one_hot(X, num_classes=5).to(torch.float32)\n",
    "        h0 = torch.zeros(self.num_layers, X.size(0), self.hidden_state_size).to(X.device)\n",
    "        \n",
    "        states, _ = self.core(X, h0)\n",
    "        logits = self.head(states[:, -1, :])\n",
    "        return torch.softmax(logits, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba650137-8b2c-4668-8eed-70c11a140203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5900aadc-fe63-4479-ad65-544d4bcfe1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88de844-1cff-4d03-8335-13105c72212c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.219199  [ 1000/100000]\n",
      "loss: 3.207131  [11000/100000]\n",
      "loss: 3.160513  [21000/100000]\n",
      "loss: 3.181263  [31000/100000]\n",
      "loss: 3.169338  [41000/100000]\n",
      "loss: 3.197101  [51000/100000]\n",
      "loss: 3.178111  [61000/100000]\n",
      "loss: 3.169788  [71000/100000]\n",
      "loss: 3.160528  [81000/100000]\n",
      "loss: 3.170960  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 11.6%, Avg loss: 3.168160 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.163949  [ 1000/100000]\n",
      "loss: 3.171055  [11000/100000]\n",
      "loss: 3.162553  [21000/100000]\n",
      "loss: 3.166800  [31000/100000]\n",
      "loss: 3.155782  [41000/100000]\n",
      "loss: 3.172868  [51000/100000]\n",
      "loss: 3.160067  [61000/100000]\n",
      "loss: 3.150602  [71000/100000]\n",
      "loss: 3.153774  [81000/100000]\n",
      "loss: 3.151710  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 11.5%, Avg loss: 3.153340 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.148552  [ 1000/100000]\n",
      "loss: 3.160189  [11000/100000]\n",
      "loss: 3.153510  [21000/100000]\n",
      "loss: 3.159347  [31000/100000]\n",
      "loss: 3.151096  [41000/100000]\n",
      "loss: 3.172873  [51000/100000]\n",
      "loss: 3.154449  [61000/100000]\n",
      "loss: 3.150340  [71000/100000]\n",
      "loss: 3.149417  [81000/100000]\n",
      "loss: 3.149716  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 11.6%, Avg loss: 3.151670 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.146340  [ 1000/100000]\n",
      "loss: 3.158133  [11000/100000]\n",
      "loss: 3.151374  [21000/100000]\n",
      "loss: 3.158749  [31000/100000]\n",
      "loss: 3.150268  [41000/100000]\n",
      "loss: 3.170257  [51000/100000]\n",
      "loss: 3.150964  [61000/100000]\n",
      "loss: 3.147229  [71000/100000]\n",
      "loss: 3.148784  [81000/100000]\n",
      "loss: 3.149465  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 11.6%, Avg loss: 3.150701 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.145673  [ 1000/100000]\n",
      "loss: 3.157029  [11000/100000]\n",
      "loss: 3.149325  [21000/100000]\n",
      "loss: 3.157514  [31000/100000]\n",
      "loss: 3.148580  [41000/100000]\n",
      "loss: 3.168423  [51000/100000]\n",
      "loss: 3.149135  [61000/100000]\n",
      "loss: 3.144312  [71000/100000]\n",
      "loss: 3.147628  [81000/100000]\n",
      "loss: 3.147352  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 12.7%, Avg loss: 3.148148 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.144328  [ 1000/100000]\n",
      "loss: 3.154799  [11000/100000]\n",
      "loss: 3.144264  [21000/100000]\n",
      "loss: 3.154868  [31000/100000]\n",
      "loss: 3.144588  [41000/100000]\n",
      "loss: 3.165234  [51000/100000]\n",
      "loss: 3.141956  [61000/100000]\n",
      "loss: 3.135480  [71000/100000]\n",
      "loss: 3.139577  [81000/100000]\n",
      "loss: 3.138194  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 15.1%, Avg loss: 3.135628 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.135291  [ 1000/100000]\n",
      "loss: 3.147617  [11000/100000]\n",
      "loss: 3.126104  [21000/100000]\n",
      "loss: 3.147666  [31000/100000]\n",
      "loss: 3.131999  [41000/100000]\n",
      "loss: 3.143729  [51000/100000]\n",
      "loss: 3.118141  [61000/100000]\n",
      "loss: 3.104836  [71000/100000]\n",
      "loss: 3.113899  [81000/100000]\n",
      "loss: 3.111027  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 19.1%, Avg loss: 3.098038 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.101048  [ 1000/100000]\n",
      "loss: 3.206700  [11000/100000]\n",
      "loss: 3.083528  [21000/100000]\n",
      "loss: 3.088213  [31000/100000]\n",
      "loss: 3.069465  [41000/100000]\n",
      "loss: 3.082794  [51000/100000]\n",
      "loss: 3.039350  [61000/100000]\n",
      "loss: 3.023176  [71000/100000]\n",
      "loss: 3.049533  [81000/100000]\n",
      "loss: 3.056262  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 26.6%, Avg loss: 3.028065 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.050137  [ 1000/100000]\n",
      "loss: 3.041708  [11000/100000]\n",
      "loss: 3.035923  [21000/100000]\n",
      "loss: 3.031000  [31000/100000]\n",
      "loss: 3.024209  [41000/100000]\n",
      "loss: 3.051547  [51000/100000]\n",
      "loss: 3.017432  [61000/100000]\n",
      "loss: 2.998813  [71000/100000]\n",
      "loss: 3.031157  [81000/100000]\n",
      "loss: 3.026398  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 26.5%, Avg loss: 3.021549 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.046849  [ 1000/100000]\n",
      "loss: 3.032306  [11000/100000]\n",
      "loss: 3.013759  [21000/100000]\n",
      "loss: 3.010885  [31000/100000]\n",
      "loss: 3.021212  [41000/100000]\n",
      "loss: 3.034348  [51000/100000]\n",
      "loss: 3.015860  [61000/100000]\n",
      "loss: 2.987844  [71000/100000]\n",
      "loss: 3.060591  [81000/100000]\n",
      "loss: 3.053024  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 26.3%, Avg loss: 3.025230 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 3.055097  [ 1000/100000]\n",
      "loss: 3.032928  [11000/100000]\n",
      "loss: 3.020591  [21000/100000]\n",
      "loss: 3.014941  [31000/100000]\n",
      "loss: 3.018570  [41000/100000]\n",
      "loss: 3.040692  [51000/100000]\n",
      "loss: 3.013245  [61000/100000]\n",
      "loss: 2.986518  [71000/100000]\n",
      "loss: 3.015155  [81000/100000]\n",
      "loss: 3.016185  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.4%, Avg loss: 3.001890 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 3.030391  [ 1000/100000]\n",
      "loss: 3.021616  [11000/100000]\n",
      "loss: 3.009676  [21000/100000]\n",
      "loss: 3.006679  [31000/100000]\n",
      "loss: 3.012796  [41000/100000]\n",
      "loss: 3.033665  [51000/100000]\n",
      "loss: 3.010844  [61000/100000]\n",
      "loss: 2.983440  [71000/100000]\n",
      "loss: 3.018341  [81000/100000]\n",
      "loss: 3.225948  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 4.1%, Avg loss: 3.222140 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 3.219382  [ 1000/100000]\n",
      "loss: 3.217066  [11000/100000]\n",
      "loss: 3.217238  [21000/100000]\n",
      "loss: 3.206090  [31000/100000]\n",
      "loss: 3.191851  [41000/100000]\n",
      "loss: 3.183631  [51000/100000]\n",
      "loss: 3.181379  [61000/100000]\n",
      "loss: 3.164738  [71000/100000]\n",
      "loss: 3.155029  [81000/100000]\n",
      "loss: 3.155717  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 11.9%, Avg loss: 3.166466 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 3.162979  [ 1000/100000]\n",
      "loss: 3.154127  [11000/100000]\n",
      "loss: 3.145771  [21000/100000]\n",
      "loss: 3.105572  [31000/100000]\n",
      "loss: 3.111427  [41000/100000]\n",
      "loss: 3.116987  [51000/100000]\n",
      "loss: 3.140901  [61000/100000]\n",
      "loss: 3.124616  [71000/100000]\n",
      "loss: 3.119007  [81000/100000]\n",
      "loss: 3.129303  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 18.4%, Avg loss: 3.106935 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 3.097090  [ 1000/100000]\n",
      "loss: 3.104198  [11000/100000]\n",
      "loss: 3.121951  [21000/100000]\n",
      "loss: 3.091178  [31000/100000]\n",
      "loss: 3.080532  [41000/100000]\n",
      "loss: 3.093878  [51000/100000]\n",
      "loss: 3.099179  [61000/100000]\n",
      "loss: 3.098416  [71000/100000]\n",
      "loss: 3.101537  [81000/100000]\n",
      "loss: 3.106343  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 3.102909 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 3.093714  [ 1000/100000]\n",
      "loss: 3.115764  [11000/100000]\n",
      "loss: 3.083908  [21000/100000]\n",
      "loss: 3.002262  [31000/100000]\n",
      "loss: 3.145391  [41000/100000]\n",
      "loss: 3.125969  [51000/100000]\n",
      "loss: 3.111394  [61000/100000]\n",
      "loss: 3.021025  [71000/100000]\n",
      "loss: 3.036734  [81000/100000]\n",
      "loss: 3.032285  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 27.1%, Avg loss: 3.017193 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 3.039751  [ 1000/100000]\n",
      "loss: 3.037675  [11000/100000]\n",
      "loss: 3.024121  [21000/100000]\n",
      "loss: 3.008070  [31000/100000]\n",
      "loss: 3.017555  [41000/100000]\n",
      "loss: 3.036011  [51000/100000]\n",
      "loss: 3.008276  [61000/100000]\n",
      "loss: 2.989475  [71000/100000]\n",
      "loss: 3.014626  [81000/100000]\n",
      "loss: 3.011672  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.1%, Avg loss: 3.003569 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 3.031930  [ 1000/100000]\n",
      "loss: 3.019211  [11000/100000]\n",
      "loss: 3.013399  [21000/100000]\n",
      "loss: 3.009885  [31000/100000]\n",
      "loss: 3.010899  [41000/100000]\n",
      "loss: 3.034684  [51000/100000]\n",
      "loss: 3.009744  [61000/100000]\n",
      "loss: 2.980249  [71000/100000]\n",
      "loss: 3.015299  [81000/100000]\n",
      "loss: 3.014107  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.1%, Avg loss: 3.004044 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 3.028038  [ 1000/100000]\n",
      "loss: 3.018327  [11000/100000]\n",
      "loss: 3.011774  [21000/100000]\n",
      "loss: 3.006233  [31000/100000]\n",
      "loss: 3.010133  [41000/100000]\n",
      "loss: 3.033643  [51000/100000]\n",
      "loss: 3.007987  [61000/100000]\n",
      "loss: 2.980808  [71000/100000]\n",
      "loss: 3.009592  [81000/100000]\n",
      "loss: 3.016802  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.4%, Avg loss: 3.000788 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 3.029835  [ 1000/100000]\n",
      "loss: 3.014922  [11000/100000]\n",
      "loss: 3.005053  [21000/100000]\n",
      "loss: 3.002286  [31000/100000]\n",
      "loss: 3.009850  [41000/100000]\n",
      "loss: 3.029398  [51000/100000]\n",
      "loss: 3.008768  [61000/100000]\n",
      "loss: 2.980175  [71000/100000]\n",
      "loss: 3.028392  [81000/100000]\n",
      "loss: 3.018774  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 27.9%, Avg loss: 3.006784 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 3.035921  [ 1000/100000]\n",
      "loss: 3.018214  [11000/100000]\n",
      "loss: 3.005074  [21000/100000]\n",
      "loss: 3.007081  [31000/100000]\n",
      "loss: 3.004842  [41000/100000]\n",
      "loss: 3.031988  [51000/100000]\n",
      "loss: 3.005871  [61000/100000]\n",
      "loss: 2.979767  [71000/100000]\n",
      "loss: 3.012591  [81000/100000]\n",
      "loss: 3.013467  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.1%, Avg loss: 3.002409 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 3.028866  [ 1000/100000]\n",
      "loss: 3.030509  [11000/100000]\n",
      "loss: 3.016979  [21000/100000]\n",
      "loss: 3.012852  [31000/100000]\n",
      "loss: 3.018008  [41000/100000]\n",
      "loss: 3.035075  [51000/100000]\n",
      "loss: 3.009409  [61000/100000]\n",
      "loss: 2.988929  [71000/100000]\n",
      "loss: 3.022511  [81000/100000]\n",
      "loss: 3.021674  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.3%, Avg loss: 3.000618 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 3.028593  [ 1000/100000]\n",
      "loss: 3.015531  [11000/100000]\n",
      "loss: 3.004095  [21000/100000]\n",
      "loss: 3.009799  [31000/100000]\n",
      "loss: 3.003758  [41000/100000]\n",
      "loss: 3.031321  [51000/100000]\n",
      "loss: 3.006886  [61000/100000]\n",
      "loss: 2.978609  [71000/100000]\n",
      "loss: 3.008820  [81000/100000]\n",
      "loss: 3.011778  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.6%, Avg loss: 2.997626 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 3.024818  [ 1000/100000]\n",
      "loss: 3.015191  [11000/100000]\n",
      "loss: 3.002144  [21000/100000]\n",
      "loss: 3.007818  [31000/100000]\n",
      "loss: 3.002966  [41000/100000]\n",
      "loss: 3.030956  [51000/100000]\n",
      "loss: 3.004208  [61000/100000]\n",
      "loss: 2.981800  [71000/100000]\n",
      "loss: 3.010777  [81000/100000]\n",
      "loss: 3.010050  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.5%, Avg loss: 2.998415 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 3.018709  [ 1000/100000]\n",
      "loss: 3.012176  [11000/100000]\n",
      "loss: 3.004508  [21000/100000]\n",
      "loss: 3.004585  [31000/100000]\n",
      "loss: 3.005893  [41000/100000]\n",
      "loss: 3.028378  [51000/100000]\n",
      "loss: 3.004592  [61000/100000]\n",
      "loss: 2.979801  [71000/100000]\n",
      "loss: 3.008520  [81000/100000]\n",
      "loss: 3.011545  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.6%, Avg loss: 2.996821 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 3.019715  [ 1000/100000]\n",
      "loss: 3.012169  [11000/100000]\n",
      "loss: 3.001084  [21000/100000]\n",
      "loss: 3.003682  [31000/100000]\n",
      "loss: 3.002008  [41000/100000]\n",
      "loss: 3.027807  [51000/100000]\n",
      "loss: 3.006182  [61000/100000]\n",
      "loss: 2.978059  [71000/100000]\n",
      "loss: 3.005153  [81000/100000]\n",
      "loss: 3.012917  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.4%, Avg loss: 2.999710 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 3.025187  [ 1000/100000]\n",
      "loss: 3.015566  [11000/100000]\n",
      "loss: 3.000403  [21000/100000]\n",
      "loss: 3.003216  [31000/100000]\n",
      "loss: 3.000655  [41000/100000]\n",
      "loss: 3.028108  [51000/100000]\n",
      "loss: 3.007956  [61000/100000]\n",
      "loss: 2.979328  [71000/100000]\n",
      "loss: 3.012997  [81000/100000]\n",
      "loss: 3.009874  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.4%, Avg loss: 2.999728 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 3.023572  [ 1000/100000]\n",
      "loss: 3.013501  [11000/100000]\n",
      "loss: 3.000914  [21000/100000]\n",
      "loss: 3.002837  [31000/100000]\n",
      "loss: 2.998153  [41000/100000]\n",
      "loss: 3.030925  [51000/100000]\n",
      "loss: 3.006227  [61000/100000]\n",
      "loss: 2.979239  [71000/100000]\n",
      "loss: 3.003972  [81000/100000]\n",
      "loss: 3.008938  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.7%, Avg loss: 2.995807 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 3.019384  [ 1000/100000]\n",
      "loss: 3.011946  [11000/100000]\n",
      "loss: 3.000388  [21000/100000]\n",
      "loss: 3.001419  [31000/100000]\n",
      "loss: 3.003398  [41000/100000]\n",
      "loss: 3.027973  [51000/100000]\n",
      "loss: 3.003067  [61000/100000]\n",
      "loss: 2.977676  [71000/100000]\n",
      "loss: 3.010191  [81000/100000]\n",
      "loss: 3.012321  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.3%, Avg loss: 3.001823 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 3.025920  [ 1000/100000]\n",
      "loss: 3.018295  [11000/100000]\n",
      "loss: 3.005525  [21000/100000]\n",
      "loss: 3.006148  [31000/100000]\n",
      "loss: 3.006362  [41000/100000]\n",
      "loss: 3.026710  [51000/100000]\n",
      "loss: 3.006854  [61000/100000]\n",
      "loss: 2.976570  [71000/100000]\n",
      "loss: 3.001750  [81000/100000]\n",
      "loss: 3.007352  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.7%, Avg loss: 2.995087 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 3.019337  [ 1000/100000]\n",
      "loss: 3.012941  [11000/100000]\n",
      "loss: 2.998457  [21000/100000]\n",
      "loss: 3.002026  [31000/100000]\n",
      "loss: 3.003968  [41000/100000]\n",
      "loss: 3.028420  [51000/100000]\n",
      "loss: 3.002636  [61000/100000]\n",
      "loss: 2.976700  [71000/100000]\n",
      "loss: 3.003692  [81000/100000]\n",
      "loss: 3.004977  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.5%, Avg loss: 2.997039 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 3.023604  [ 1000/100000]\n",
      "loss: 3.015502  [11000/100000]\n",
      "loss: 3.003743  [21000/100000]\n",
      "loss: 3.005427  [31000/100000]\n",
      "loss: 3.005210  [41000/100000]\n",
      "loss: 3.027118  [51000/100000]\n",
      "loss: 3.002799  [61000/100000]\n",
      "loss: 2.977401  [71000/100000]\n",
      "loss: 3.017713  [81000/100000]\n",
      "loss: 3.014845  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.3%, Avg loss: 3.000552 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 3.022674  [ 1000/100000]\n",
      "loss: 3.013446  [11000/100000]\n",
      "loss: 2.997636  [21000/100000]\n",
      "loss: 3.006386  [31000/100000]\n",
      "loss: 3.004710  [41000/100000]\n",
      "loss: 3.024988  [51000/100000]\n",
      "loss: 3.006073  [61000/100000]\n",
      "loss: 2.977677  [71000/100000]\n",
      "loss: 3.004572  [81000/100000]\n",
      "loss: 3.006882  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.7%, Avg loss: 2.995224 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 3.019616  [ 1000/100000]\n",
      "loss: 3.009118  [11000/100000]\n",
      "loss: 3.000478  [21000/100000]\n",
      "loss: 3.004590  [31000/100000]\n",
      "loss: 3.007394  [41000/100000]\n",
      "loss: 3.034165  [51000/100000]\n",
      "loss: 3.059227  [61000/100000]\n",
      "loss: 3.014100  [71000/100000]\n",
      "loss: 3.033633  [81000/100000]\n",
      "loss: 3.025924  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 27.3%, Avg loss: 3.012817 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 3.039711  [ 1000/100000]\n",
      "loss: 3.021014  [11000/100000]\n",
      "loss: 3.017545  [21000/100000]\n",
      "loss: 3.006984  [31000/100000]\n",
      "loss: 3.011062  [41000/100000]\n",
      "loss: 3.037914  [51000/100000]\n",
      "loss: 3.011055  [61000/100000]\n",
      "loss: 2.980110  [71000/100000]\n",
      "loss: 3.011540  [81000/100000]\n",
      "loss: 3.009588  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.4%, Avg loss: 2.999379 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 3.023870  [ 1000/100000]\n",
      "loss: 3.018085  [11000/100000]\n",
      "loss: 3.002898  [21000/100000]\n",
      "loss: 3.008403  [31000/100000]\n",
      "loss: 3.005990  [41000/100000]\n",
      "loss: 3.031461  [51000/100000]\n",
      "loss: 3.004826  [61000/100000]\n",
      "loss: 2.976084  [71000/100000]\n",
      "loss: 3.009882  [81000/100000]\n",
      "loss: 3.005479  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.4%, Avg loss: 2.998444 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 3.022399  [ 1000/100000]\n",
      "loss: 3.013939  [11000/100000]\n",
      "loss: 3.003872  [21000/100000]\n",
      "loss: 3.004056  [31000/100000]\n",
      "loss: 3.003032  [41000/100000]\n",
      "loss: 3.025443  [51000/100000]\n",
      "loss: 3.003021  [61000/100000]\n",
      "loss: 2.977281  [71000/100000]\n",
      "loss: 3.008236  [81000/100000]\n",
      "loss: 3.011580  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.2%, Avg loss: 2.999843 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 3.025785  [ 1000/100000]\n",
      "loss: 3.015946  [11000/100000]\n",
      "loss: 3.004920  [21000/100000]\n",
      "loss: 3.003796  [31000/100000]\n",
      "loss: 3.006207  [41000/100000]\n",
      "loss: 3.031796  [51000/100000]\n",
      "loss: 3.007013  [61000/100000]\n",
      "loss: 2.977699  [71000/100000]\n",
      "loss: 3.005649  [81000/100000]\n",
      "loss: 3.030912  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 27.8%, Avg loss: 3.007001 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 3.031671  [ 1000/100000]\n",
      "loss: 3.013610  [11000/100000]\n",
      "loss: 3.001215  [21000/100000]\n",
      "loss: 3.003082  [31000/100000]\n",
      "loss: 3.003973  [41000/100000]\n",
      "loss: 3.059836  [51000/100000]\n",
      "loss: 3.026189  [61000/100000]\n",
      "loss: 2.986027  [71000/100000]\n",
      "loss: 3.020379  [81000/100000]\n",
      "loss: 3.014868  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 27.2%, Avg loss: 3.010335 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 3.035492  [ 1000/100000]\n",
      "loss: 3.020890  [11000/100000]\n",
      "loss: 3.010357  [21000/100000]\n",
      "loss: 3.005476  [31000/100000]\n",
      "loss: 3.009721  [41000/100000]\n",
      "loss: 3.030154  [51000/100000]\n",
      "loss: 3.007783  [61000/100000]\n",
      "loss: 2.979970  [71000/100000]\n",
      "loss: 3.009947  [81000/100000]\n",
      "loss: 3.013939  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.4%, Avg loss: 2.999087 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 3.020861  [ 1000/100000]\n",
      "loss: 3.014842  [11000/100000]\n",
      "loss: 3.002765  [21000/100000]\n",
      "loss: 3.001436  [31000/100000]\n",
      "loss: 3.003586  [41000/100000]\n",
      "loss: 3.026044  [51000/100000]\n",
      "loss: 3.005926  [61000/100000]\n",
      "loss: 2.974995  [71000/100000]\n",
      "loss: 3.003382  [81000/100000]\n",
      "loss: 3.009121  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.6%, Avg loss: 2.996857 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 3.019370  [ 1000/100000]\n",
      "loss: 3.019795  [11000/100000]\n",
      "loss: 2.999495  [21000/100000]\n",
      "loss: 3.000369  [31000/100000]\n",
      "loss: 3.002625  [41000/100000]\n",
      "loss: 3.029027  [51000/100000]\n",
      "loss: 3.003717  [61000/100000]\n",
      "loss: 2.975888  [71000/100000]\n",
      "loss: 3.009045  [81000/100000]\n",
      "loss: 3.011758  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.4%, Avg loss: 2.998327 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 3.023161  [ 1000/100000]\n",
      "loss: 3.015191  [11000/100000]\n",
      "loss: 2.999777  [21000/100000]\n",
      "loss: 2.998992  [31000/100000]\n",
      "loss: 3.000168  [41000/100000]\n",
      "loss: 3.025313  [51000/100000]\n",
      "loss: 3.003786  [61000/100000]\n",
      "loss: 2.975994  [71000/100000]\n",
      "loss: 3.004454  [81000/100000]\n",
      "loss: 3.012470  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.4%, Avg loss: 2.998983 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 3.024119  [ 1000/100000]\n",
      "loss: 3.011337  [11000/100000]\n",
      "loss: 2.998657  [21000/100000]\n",
      "loss: 3.000551  [31000/100000]\n",
      "loss: 3.004137  [41000/100000]\n",
      "loss: 3.026896  [51000/100000]\n",
      "loss: 3.004734  [61000/100000]\n",
      "loss: 2.975970  [71000/100000]\n",
      "loss: 3.003120  [81000/100000]\n",
      "loss: 3.008719  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.3%, Avg loss: 2.999683 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 3.024511  [ 1000/100000]\n",
      "loss: 3.014211  [11000/100000]\n",
      "loss: 2.999708  [21000/100000]\n",
      "loss: 2.999816  [31000/100000]\n",
      "loss: 3.000800  [41000/100000]\n",
      "loss: 3.026500  [51000/100000]\n",
      "loss: 3.003186  [61000/100000]\n",
      "loss: 2.976729  [71000/100000]\n",
      "loss: 3.001126  [81000/100000]\n",
      "loss: 3.007542  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.7%, Avg loss: 2.995686 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 3.020959  [ 1000/100000]\n",
      "loss: 3.009501  [11000/100000]\n",
      "loss: 2.999428  [21000/100000]\n",
      "loss: 2.999677  [31000/100000]\n",
      "loss: 3.000753  [41000/100000]\n",
      "loss: 3.030692  [51000/100000]\n",
      "loss: 3.001604  [61000/100000]\n",
      "loss: 2.976443  [71000/100000]\n",
      "loss: 3.011549  [81000/100000]\n",
      "loss: 3.009436  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.7%, Avg loss: 2.996018 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 3.018161  [ 1000/100000]\n",
      "loss: 3.012447  [11000/100000]\n",
      "loss: 2.998078  [21000/100000]\n",
      "loss: 3.000516  [31000/100000]\n",
      "loss: 3.005918  [41000/100000]\n",
      "loss: 3.025939  [51000/100000]\n",
      "loss: 3.005950  [61000/100000]\n",
      "loss: 2.974290  [71000/100000]\n",
      "loss: 3.000213  [81000/100000]\n",
      "loss: 3.007194  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.8%, Avg loss: 2.995161 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 3.020624  [ 1000/100000]\n",
      "loss: 3.026162  [11000/100000]\n",
      "loss: 3.014856  [21000/100000]\n",
      "loss: 3.009395  [31000/100000]\n",
      "loss: 3.015177  [41000/100000]\n",
      "loss: 3.035317  [51000/100000]\n",
      "loss: 3.011052  [61000/100000]\n",
      "loss: 2.986743  [71000/100000]\n",
      "loss: 3.014488  [81000/100000]\n",
      "loss: 3.010152  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.0%, Avg loss: 3.004264 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 3.024175  [ 1000/100000]\n",
      "loss: 3.017254  [11000/100000]\n",
      "loss: 3.001332  [21000/100000]\n",
      "loss: 3.004252  [31000/100000]\n",
      "loss: 3.007374  [41000/100000]\n",
      "loss: 3.030405  [51000/100000]\n",
      "loss: 3.006474  [61000/100000]\n",
      "loss: 2.984247  [71000/100000]\n",
      "loss: 3.009709  [81000/100000]\n",
      "loss: 3.018331  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.7%, Avg loss: 2.997103 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 3.025558  [ 1000/100000]\n",
      "loss: 3.016574  [11000/100000]\n",
      "loss: 3.004787  [21000/100000]\n",
      "loss: 3.003868  [31000/100000]\n",
      "loss: 3.003458  [41000/100000]\n",
      "loss: 3.031337  [51000/100000]\n",
      "loss: 3.008687  [61000/100000]\n",
      "loss: 2.982073  [71000/100000]\n",
      "loss: 3.012319  [81000/100000]\n",
      "loss: 3.012909  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.6%, Avg loss: 2.998173 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 3.019952  [ 1000/100000]\n",
      "loss: 3.012547  [11000/100000]\n",
      "loss: 3.003323  [21000/100000]\n",
      "loss: 3.002433  [31000/100000]\n",
      "loss: 3.002752  [41000/100000]\n",
      "loss: 3.027656  [51000/100000]\n",
      "loss: 3.005522  [61000/100000]\n",
      "loss: 2.976504  [71000/100000]\n",
      "loss: 3.006227  [81000/100000]\n",
      "loss: 3.009035  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.7%, Avg loss: 2.996481 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 3.019677  [ 1000/100000]\n",
      "loss: 3.011654  [11000/100000]\n",
      "loss: 3.003296  [21000/100000]\n",
      "loss: 3.002713  [31000/100000]\n",
      "loss: 3.008953  [41000/100000]\n",
      "loss: 3.031439  [51000/100000]\n",
      "loss: 3.010663  [61000/100000]\n",
      "loss: 2.979444  [71000/100000]\n",
      "loss: 3.003313  [81000/100000]\n",
      "loss: 3.011927  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.8%, Avg loss: 2.995859 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 3.020285  [ 1000/100000]\n",
      "loss: 3.009647  [11000/100000]\n",
      "loss: 3.004569  [21000/100000]\n",
      "loss: 3.001155  [31000/100000]\n",
      "loss: 3.002770  [41000/100000]\n",
      "loss: 3.026784  [51000/100000]\n",
      "loss: 3.004485  [61000/100000]\n",
      "loss: 2.977959  [71000/100000]\n",
      "loss: 3.002464  [81000/100000]\n",
      "loss: 3.008329  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.6%, Avg loss: 2.996359 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 3.016508  [ 1000/100000]\n",
      "loss: 3.011682  [11000/100000]\n",
      "loss: 3.004366  [21000/100000]\n",
      "loss: 3.004119  [31000/100000]\n",
      "loss: 3.005671  [41000/100000]\n",
      "loss: 3.032681  [51000/100000]\n",
      "loss: 3.008690  [61000/100000]\n",
      "loss: 2.975724  [71000/100000]\n",
      "loss: 2.998844  [81000/100000]\n",
      "loss: 3.005935  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.8%, Avg loss: 2.995466 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 3.014624  [ 1000/100000]\n",
      "loss: 3.015058  [11000/100000]\n",
      "loss: 3.002860  [21000/100000]\n",
      "loss: 3.002319  [31000/100000]\n",
      "loss: 3.005937  [41000/100000]\n",
      "loss: 3.025870  [51000/100000]\n",
      "loss: 3.009258  [61000/100000]\n",
      "loss: 2.980191  [71000/100000]\n",
      "loss: 2.999621  [81000/100000]\n",
      "loss: 3.008726  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.9%, Avg loss: 2.994494 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 3.011930  [ 1000/100000]\n",
      "loss: 3.011859  [11000/100000]\n",
      "loss: 2.999753  [21000/100000]\n",
      "loss: 2.997981  [31000/100000]\n",
      "loss: 3.005823  [41000/100000]\n",
      "loss: 3.023928  [51000/100000]\n",
      "loss: 3.010567  [61000/100000]\n",
      "loss: 2.979684  [71000/100000]\n",
      "loss: 2.997293  [81000/100000]\n",
      "loss: 3.009895  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 29.0%, Avg loss: 2.994044 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 3.010372  [ 1000/100000]\n",
      "loss: 3.012163  [11000/100000]\n",
      "loss: 2.998417  [21000/100000]\n",
      "loss: 2.995684  [31000/100000]\n",
      "loss: 3.001636  [41000/100000]\n",
      "loss: 3.022950  [51000/100000]\n",
      "loss: 3.004345  [61000/100000]\n",
      "loss: 2.975910  [71000/100000]\n",
      "loss: 2.994770  [81000/100000]\n",
      "loss: 3.007550  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 29.0%, Avg loss: 2.993013 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 3.011512  [ 1000/100000]\n",
      "loss: 3.007618  [11000/100000]\n",
      "loss: 2.996518  [21000/100000]\n",
      "loss: 2.997565  [31000/100000]\n",
      "loss: 3.004410  [41000/100000]\n",
      "loss: 3.039464  [51000/100000]\n",
      "loss: 3.007028  [61000/100000]\n",
      "loss: 2.977158  [71000/100000]\n",
      "loss: 2.996933  [81000/100000]\n",
      "loss: 3.006540  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.6%, Avg loss: 2.997287 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 3.017881  [ 1000/100000]\n",
      "loss: 3.007385  [11000/100000]\n",
      "loss: 2.997288  [21000/100000]\n",
      "loss: 2.993924  [31000/100000]\n",
      "loss: 3.001890  [41000/100000]\n",
      "loss: 3.020005  [51000/100000]\n",
      "loss: 3.004114  [61000/100000]\n",
      "loss: 2.976933  [71000/100000]\n",
      "loss: 2.992196  [81000/100000]\n",
      "loss: 3.004363  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.9%, Avg loss: 2.994683 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 3.014183  [ 1000/100000]\n",
      "loss: 3.014092  [11000/100000]\n",
      "loss: 2.991883  [21000/100000]\n",
      "loss: 2.995387  [31000/100000]\n",
      "loss: 2.997610  [41000/100000]\n",
      "loss: 3.021670  [51000/100000]\n",
      "loss: 3.022156  [61000/100000]\n",
      "loss: 2.987529  [71000/100000]\n",
      "loss: 3.000371  [81000/100000]\n",
      "loss: 3.006847  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.7%, Avg loss: 2.996565 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 3.020828  [ 1000/100000]\n",
      "loss: 3.011706  [11000/100000]\n",
      "loss: 2.996936  [21000/100000]\n",
      "loss: 2.996676  [31000/100000]\n",
      "loss: 2.999550  [41000/100000]\n",
      "loss: 3.017567  [51000/100000]\n",
      "loss: 3.013179  [61000/100000]\n",
      "loss: 2.980455  [71000/100000]\n",
      "loss: 2.993101  [81000/100000]\n",
      "loss: 2.998574  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.9%, Avg loss: 2.993551 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 3.018610  [ 1000/100000]\n",
      "loss: 3.004133  [11000/100000]\n",
      "loss: 2.994479  [21000/100000]\n",
      "loss: 2.996009  [31000/100000]\n",
      "loss: 2.994508  [41000/100000]\n",
      "loss: 3.016972  [51000/100000]\n",
      "loss: 3.005126  [61000/100000]\n",
      "loss: 2.977878  [71000/100000]\n",
      "loss: 2.998491  [81000/100000]\n",
      "loss: 3.002525  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.9%, Avg loss: 2.993276 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 3.017314  [ 1000/100000]\n",
      "loss: 3.013145  [11000/100000]\n",
      "loss: 2.993699  [21000/100000]\n",
      "loss: 2.995710  [31000/100000]\n",
      "loss: 2.996903  [41000/100000]\n",
      "loss: 3.015542  [51000/100000]\n",
      "loss: 3.004116  [61000/100000]\n",
      "loss: 2.973364  [71000/100000]\n",
      "loss: 2.991475  [81000/100000]\n",
      "loss: 3.038251  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 26.8%, Avg loss: 3.019522 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 3.036273  [ 1000/100000]\n",
      "loss: 3.028819  [11000/100000]\n",
      "loss: 3.018591  [21000/100000]\n",
      "loss: 3.007542  [31000/100000]\n",
      "loss: 3.015542  [41000/100000]\n",
      "loss: 3.037827  [51000/100000]\n",
      "loss: 3.011356  [61000/100000]\n",
      "loss: 2.990511  [71000/100000]\n",
      "loss: 3.012894  [81000/100000]\n",
      "loss: 3.009057  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.2%, Avg loss: 3.001148 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 3.023899  [ 1000/100000]\n",
      "loss: 3.014871  [11000/100000]\n",
      "loss: 3.008141  [21000/100000]\n",
      "loss: 3.000309  [31000/100000]\n",
      "loss: 3.008486  [41000/100000]\n",
      "loss: 3.024544  [51000/100000]\n",
      "loss: 3.006299  [61000/100000]\n",
      "loss: 2.983362  [71000/100000]\n",
      "loss: 3.003162  [81000/100000]\n",
      "loss: 3.018937  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 27.8%, Avg loss: 3.005668 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 3.030962  [ 1000/100000]\n",
      "loss: 3.014427  [11000/100000]\n",
      "loss: 3.008198  [21000/100000]\n",
      "loss: 3.021052  [31000/100000]\n",
      "loss: 3.035780  [41000/100000]\n",
      "loss: 3.049593  [51000/100000]\n",
      "loss: 3.015950  [61000/100000]\n",
      "loss: 2.989669  [71000/100000]\n",
      "loss: 3.011396  [81000/100000]\n",
      "loss: 3.012566  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.2%, Avg loss: 3.001225 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 3.025526  [ 1000/100000]\n",
      "loss: 3.012483  [11000/100000]\n",
      "loss: 3.004883  [21000/100000]\n",
      "loss: 3.002772  [31000/100000]\n",
      "loss: 3.009535  [41000/100000]\n",
      "loss: 3.029502  [51000/100000]\n",
      "loss: 3.006532  [61000/100000]\n",
      "loss: 2.982080  [71000/100000]\n",
      "loss: 3.004148  [81000/100000]\n",
      "loss: 3.006260  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.7%, Avg loss: 2.994703 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 3.017724  [ 1000/100000]\n",
      "loss: 3.014609  [11000/100000]\n",
      "loss: 3.003206  [21000/100000]\n",
      "loss: 2.999614  [31000/100000]\n",
      "loss: 3.003295  [41000/100000]\n",
      "loss: 3.024728  [51000/100000]\n",
      "loss: 3.006465  [61000/100000]\n",
      "loss: 2.978396  [71000/100000]\n",
      "loss: 3.007142  [81000/100000]\n",
      "loss: 3.012782  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.5%, Avg loss: 2.997896 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 3.019632  [ 1000/100000]\n",
      "loss: 3.009015  [11000/100000]\n",
      "loss: 3.000904  [21000/100000]\n",
      "loss: 2.997311  [31000/100000]\n",
      "loss: 3.002424  [41000/100000]\n",
      "loss: 3.022882  [51000/100000]\n",
      "loss: 3.005719  [61000/100000]\n",
      "loss: 2.979701  [71000/100000]\n",
      "loss: 2.999028  [81000/100000]\n",
      "loss: 3.003950  [91000/100000]\n",
      "Test Error: \n",
      " Accuracy: 28.2%, Avg loss: 3.000194 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 3.019873  [ 1000/100000]\n",
      "loss: 3.014988  [11000/100000]\n",
      "loss: 3.008845  [21000/100000]\n",
      "loss: 2.998464  [31000/100000]\n",
      "loss: 3.005607  [41000/100000]\n",
      "loss: 3.025721  [51000/100000]\n",
      "loss: 3.005822  [61000/100000]\n",
      "loss: 2.978569  [71000/100000]\n",
      "loss: 2.992952  [81000/100000]\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "batch_size = 1000\n",
    "epochs = 100\n",
    "train_sample_size = 100_000\n",
    "test_sample_size = 10_000\n",
    "\n",
    "n_back = 0\n",
    "\n",
    "train_dataloader = DataLoader(create_n_back_dataset(train_sample_size, n_back), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(create_n_back_dataset(test_sample_size, n_back), batch_size=batch_size)\n",
    "\n",
    "model = GRUExplorer(128, num_layers=2).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33244e29-2a13-4f3e-b4da-31bc1d5e6cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
